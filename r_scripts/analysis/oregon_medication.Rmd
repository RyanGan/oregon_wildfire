---
title: "Oregon 2013 Medication for Asthma Inhalers"
author: "Jingyang Liu"
date: "May 17, 2017"
output: html_document
---

```{r library, include=FALSE, echo=FALSE}
library(tidyverse)
# library(data.table)
library(survival)
library(ggplot2)
library(htmlTable)
library(knitr)
library(broom)
library(lme4)
library(lubridate) # date

# two-stage distributed lag model libraries
library(dlnm)
library(mvmeta)
library(splines)

```


## Overview
For this research I have the Oregon All Payer All Claims (APAC) data set in 2013. I want to research on the effects of wildfire smoke on pharmacy outcome of asthma. NDC (National Drug Code) is the code that the data set offered. The standard NDC I use the link below, which is a ndc list in 2013, which fits my original data set. 
(http://ww2.ncqa.org/hedis-quality-measurement/hedis-measures/hedis-2013/hedis-2013-final-ndc-lists)

The data cleaning and casecrossover study are huge computation tasks, so they are done with server, the following work is done with local R.


## Method Description

In these comparisons, we examine various methods of smoke PM2.5 estimations and associations with health outcomes using a time-stratified case-crossover study design. Pharmacy outcomes for a patient with a primary diagnosis of cardiopulmonary health outcomes and their date of admission (index time) were identified. We then created counterfactual observations for each patient on the same day of the week for the entire wildfire season (May 1st to Sep 30th, 2013). For patients who have a index time before May 1, 2013 or after September 30, 2013, their referent observations before or after these dates will be excluded as I will not be able to assign estimates of PM2.5 to these referent observations.

1. Data cleaning for health outcomes

There are about 77 million claims in the total data set. Some have the NDC but another are null or missing because people are going for pharmacy or seeing the doctor. So I choose the claims in Oregon State with ndc existing, which is about 23 million claims. Also, the POS (Place of service code) all show "pharmacy" type, comparing to the previous health disease outcomes we limit the "emergency visit" type or "urgent care" type.

For ndc, I choose the people who use the beta 2 agonists (one inhaler) for the day's first visit to form the sample. Because the ndc csv file has more information than what I need, I filter the ndc file by SQLite Studio (code and steps not attached) to a file only containing the beta 2 agonists medication information. 

After choosing the claims with beta 2 agonists, the data set is reduced to 232,665. After choosing people's each day's first visit and limit the wildfire season dates (May 1st, 2013 to September 30th, 2013), the data set is the final data set we research on, containing  only 24,538 claims.

2. Exposure methods for smoke model

In this research, we focus on the GWR method (geographically weighted ridge regression). There are also WRF-Chem model (which substracts WRF-chem from the Weather Research and Forecasting with Chemistry no fire emission). For the WRF-Chem variable with the 'smoke' designator, this is WRF-Chem - WRF-Chem no fire. For Geo-Weighted Regression and Kriging model, with 'smk' designator, I subtracted off the 'Background' estimates of smoke, which I believe are the monthly averages of PM2.5 for a given grid. However, the 'Background' is the mean of total period from May 1st to Sep 30th 2013 so I have to assign the mean for every day. To reduce the occurance error and compare the differences I will analyze all three models.

3. Analytic method

We use the conditional logistic regression model using the survival package in R. Each conditional logistic regression model accounts for the subject, and adjusts for temperature from the WRF-Chem model. The conditional logistic regression model \beta represents the change in risk of an pharmacy event associated with a short-term unit increase in exposure, and can be calculated as an average difference between exposure at the index time and a weighted average of exposure at all times in the referent window. 

```{r import original data, eval=FALSE, echo=FALSE}
### Import whole data set ------------------------------------------------------
read_path <- paste0("../../../data/data_original/gan_episodes_of_care.txt")
start_time <- Sys.time()
oregon_df <- fread(read_path, sep = "|", showProgress = T) 
stop_time <-  Sys.time() - start_time 
# time it took
stop_time # 7 mins

## Basic cleaning
start_time <- Sys.time()
oregon_df2 <- oregon_df %>% 
  filter((!ndc=="")&(!ndc=="*NULL*")) %>% 
  # filter State is Oregon
  filter(STATE=="OR")
stop_time <-  Sys.time() - start_time 
# time it took
stop_time # 40 secs

write_path <- paste0('../../../data/data_new/',
                     'oregon_ndc.csv')
write_csv(oregon_df2, write_path)
```

### Make category index for beta-2 agonists.
First I filtered the whole data set with ndc existing and only Oregon state. Then there are about 24 million claims left. Then I filtered the data set with only beta-2-agonists and found about 233 thousand claims (83787 unique person). By using these unique personkey, I found the claims of them in the total data set, which is about 8.9 million claims. This the data set that I use for the category classification.


```{r import filtered original data, eval=FALSE, echo=FALSE}
### Import whole data set ------------------------------------------------------
read_path <- paste0("../../../data/data_original/gan_episodes_of_care.txt")
start_time <- Sys.time()
oregon_df <- fread(read_path, sep = "|", showProgress = T) 
stop_time <-  Sys.time() - start_time 
# time it took
stop_time # 7 mins

### Import NDC data set --------------------------------------------------------
read_path <- paste0("../../../data/data_new/oregon_ndc.csv")
oregon_ndc <- read_csv(read_path)
dim(oregon_ndc) # 23330714 obs

## Import Asthma NDC table
read_path2 <- paste0("../../../data/data_new/ndc_2013_beta_2_agonists.csv")
inhaler_ndc <- read_csv(read_path2, col_names = FALSE)

colnames(inhaler_ndc) <- c("ndc_code", "brand_name", "generic_product_name", 
                          "route", "category", "drug_id")

# convert to vector
ndc_codes <- as.vector(as.matrix(inhaler_ndc$ndc_code))

oregon_beta <- oregon_ndc %>%
  filter(ndc %in% ndc_codes) # 232665, unique personkey 83787

oregon_beta_df <- oregon_beta %>% 
  group_by(personkey) %>% 
  arrange(personkey, fromdate, line) %>% 
  mutate(num_visit = dense_rank(fromdate)) %>%
  arrange(personkey, num_visit) %>% 
  select(personkey, clmid, num_visit) %>% 
  unique() %>% 
  full_join(oregon_beta, by = c("personkey", "clmid")) %>% 
  arrange(personkey, clmid, line, fromdate) %>% 
  filter(row_number() == 1) %>%
  # add new transverted from date
  mutate(dates = as.Date(fromdate, "%m/%d/%Y")) # 83787 (same)


oregon_df_ndc <- oregon_df %>%
  filter(personkey %in% oregon_beta$personkey) # 8909892

### Import ICD9 code
icd9_key <- read_excel("../../../data/data_original/CMS32_DESC_LONG_SHORT_DX.xlsx") %>% 
  # rename the terrible variable names
  select(dx_code = 1, long_desc = 2, short_desc = 3)

# sort by icd9 code add row variable 
icd9_key$X <- NULL
icd9_key <- arrange(icd9_key, dx_code) %>%
  mutate(n = as.numeric(row.names(icd9_key)))

### without ICD-9
or_ndc_no_icd <- oregon_df_ndc %>%
  filter(dx1=="*NULL*" &
         dx2=="*NULL*" &
         dx3=="*NULL*" &
         dx4=="*NULL*" &
         dx5=="*NULL*" &
         dx6=="*NULL*" &
         dx7=="*NULL*" &
         dx8=="*NULL*" &
         dx9=="*NULL*" &
         dx10=="*NULL*" &
         dx11=="" &
         dx12=="" &
         dx13=="" )

length(or_ndc_no_icd$personkey) # 3656720 claims
length(unique(or_ndc_no_icd$personkey)) # 83787



or_no_ndc_no_icd <- oregon_df %>%
  filter(dx1=="*NULL*" &
         dx2=="*NULL*" &
         dx3=="*NULL*" &
         dx4=="*NULL*" &
         dx5=="*NULL*" &
         dx6=="*NULL*" &
         dx7=="*NULL*" &
         dx8=="*NULL*" &
         dx9=="*NULL*" &
         dx10=="*NULL*" &
         dx11=="" &
         dx12=="" &
         dx13=="") %>%
  filter(ndc=="" |
         ndc=="*NULL*") # 1057022 missing in total data set
         

or_ndc_all_miss <- oregon_df_ndc %>%
  filter(dx1=="*NULL*" &
         dx2=="*NULL*" &
         dx3=="*NULL*" &
         dx4=="*NULL*" &
         dx5=="*NULL*" &
         dx6=="*NULL*" &
         dx7=="*NULL*" &
         dx8=="*NULL*" &
         dx9=="*NULL*" &
         dx10=="*NULL*" &
         dx11=="" &
         dx12=="" &
         dx13=="") %>%
  filter(ndc=="" |
         ndc=="*NULL*") # 20269 missing in total data set

or_ndc_all_miss_id <- or_ndc_asthma_df %>%
  filter(personkey %in% unique(or_ndc_copd_df$personkey)) %>% # 7279 person
  select(personkey)

oregon_ndc_dx <- oregon_ndc %>%
    filter(dx1!="*NULL*" |
         dx2!="*NULL*" |
         dx3!="*NULL*" |
         dx4!="*NULL*" |
         dx5!="*NULL*" |
         dx6!="*NULL*" |
         dx7!="*NULL*" |
         dx8!="*NULL*" |
         dx9!="*NULL*" |
         dx10!="*NULL*" |
         dx11!="" |
         dx12!="" |
         dx13!="" ) # 0 claims 


### asthma
which(icd9_key$dx_code == '49300') # start of asthma is row 5206
which(icd9_key$dx_code == '49392') # end of asthma is row 5219

# limit just to asthma code and just the diagnosis column
icd9_check <- icd9_key %>%
  filter(n >= 5206 & n <= 5219) 
icd9_check

asthma_icd9 <- filter(icd9_key, n >= 5206 & n <= 5219) %>%
  select(dx_code)
# convert to vector
asthma_icd9 <- as.vector(as.matrix(asthma_icd9))   

# now can I make a new variable, asthma1, that indicates an asthma claim?
or_ndc_asthma_df <- oregon_df_ndc %>%
  filter(dx1 %in% asthma_icd9 |
         dx2 %in% asthma_icd9 |
         dx3 %in% asthma_icd9 |
         dx4 %in% asthma_icd9 |
         dx5 %in% asthma_icd9 |
         dx6 %in% asthma_icd9 |
         dx7 %in% asthma_icd9 |
         dx8 %in% asthma_icd9 |
         dx9 %in% asthma_icd9 |
         dx10 %in% asthma_icd9 |
         dx11 %in% asthma_icd9 |
         dx12 %in% asthma_icd9 |
         dx13 %in% asthma_icd9) # 375451, unique personkey: 45165


### COPD
copd_icd9 <- c('490', '4910','4911','49120','49121','49122','4918','4919', '4920',
               '4928', '4940', '4941', '496') 

# now can I make a new variable, asthma1, that indicates an asthma claim?
or_ndc_copd_df <- oregon_df_ndc %>%
  filter(dx1 %in% copd_icd9 |
         dx2 %in% copd_icd9 |
         dx3 %in% copd_icd9 |
         dx4 %in% copd_icd9 |
         dx5 %in% copd_icd9 |
         dx6 %in% copd_icd9 |
         dx7 %in% copd_icd9 |
         dx8 %in% copd_icd9 |
         dx9 %in% copd_icd9 |
         dx10 %in% copd_icd9 |
         dx11 %in% copd_icd9 |
         dx12 %in% copd_icd9 |
         dx13 %in% copd_icd9) # 361738, unique personkey: 18626

### asthma or copd
or_or_asthma_copd <- oregon_df_ndc %>%
  filter(dx1 %in% asthma_icd9 |
         dx2 %in% asthma_icd9 |
         dx3 %in% asthma_icd9 |
         dx4 %in% asthma_icd9 |
         dx5 %in% asthma_icd9 |
         dx6 %in% asthma_icd9 |
         dx7 %in% asthma_icd9 |
         dx8 %in% asthma_icd9 |
         dx9 %in% asthma_icd9 |
         dx10 %in% asthma_icd9 |
         dx11 %in% asthma_icd9 |
         dx12 %in% asthma_icd9 |
         dx13 %in% asthma_icd9 |
         dx1 %in% copd_icd9 |
         dx2 %in% copd_icd9 |
         dx3 %in% copd_icd9 |
         dx4 %in% copd_icd9 |
         dx5 %in% copd_icd9 |
         dx6 %in% copd_icd9 |
         dx7 %in% copd_icd9 |
         dx8 %in% copd_icd9 |
         dx9 %in% copd_icd9 |
         dx10 %in% copd_icd9 |
         dx11 %in% copd_icd9 |
         dx12 %in% copd_icd9 | 
         dx13 %in% copd_icd9) # 722107 , unique personkey: 56512

# 45165+ 18626 - 56512
# [1] 7279 on both asthma and copd

### Both asthma and copd
length(unique(or_or_asthma_copd$personkey))
length(unique(or_ndc_asthma_df$personkey))
length(unique(or_ndc_copd_df$personkey))

or_with_icd <- oregon_df_ndc %>%
  filter(!dx1=="*NULL*" |
         !dx2=="*NULL*" |
         !dx3=="*NULL*" |
         !dx4=="*NULL*" |
         !dx5=="*NULL*" |
         !dx6=="*NULL*" |
         !dx7=="*NULL*" |
         !dx8=="*NULL*" |
         !dx9=="*NULL*" |
         !dx10=="*NULL*" |
         !dx11=="" |
         !dx12=="" |
         !dx13=="" )

asthma_copd_both_id <- or_ndc_asthma_df %>%
  filter(personkey %in% unique(or_ndc_copd_df$personkey)) %>% # 7279 person
  select(personkey) %>%
  unique() %>%
  mutate(index="both")
  
### Only asthma
asthma_only_id <- or_ndc_asthma_df %>%
  filter(!personkey %in% asthma_copd_both_id$personkey) %>% # 37886 person
  select(personkey) %>%
  unique() %>%
  mutate(index="asthma")


### Only copd
copd_only_id <- or_ndc_copd_df %>%
  filter(!personkey %in% asthma_copd_both_id$personkey) %>% # 11347 person
  select(personkey) %>%
  unique() %>%
  mutate(index="copd")


### Other
other_disease_id <- oregon_df_ndc %>%
  filter(!personkey %in% or_or_asthma_copd$personkey) %>% # 27275 person
  select(personkey) %>%
  unique() %>%
  mutate(index="other")

id_index <- bind_rows(asthma_copd_both_id, asthma_only_id, copd_only_id, other_disease_id)

## Join the index with beta 2 ndc claims
oregon_beta_index <- oregon_beta %>%
  left_join(id_index, by="personkey")
summary(as.factor(oregon_beta_index$index))

write_path3 <- paste0('../../../data/data_new/',
                     'oregon_beta_ndc_index.csv')
write_csv(oregon_beta_index, write_path3) 


## Join with original data and indicator for 4 categories
oregon_ndc_index <- oregon_df_ndc %>%
  left_join(id_index, by="personkey")
summary(as.factor(oregon_ndc_index$index))

### Check
or_ndc_asthma_copd_sum <- oregon_ndc_index %>%
  mutate(asthma1 = ifelse(dx1 %in% asthma_icd9, 1, 0),
         asthma2 = ifelse(dx2 %in% asthma_icd9, 1, 0),
         asthma3 = ifelse(dx3 %in% asthma_icd9, 1, 0),
         asthma4 = ifelse(dx4 %in% asthma_icd9, 1, 0),
         asthma5 = ifelse(dx5 %in% asthma_icd9, 1, 0),
         asthma6 = ifelse(dx6 %in% asthma_icd9, 1, 0),
         asthma7 = ifelse(dx7 %in% asthma_icd9, 1, 0),
         asthma8 = ifelse(dx8 %in% asthma_icd9, 1, 0),
         asthma9 = ifelse(dx9 %in% asthma_icd9, 1, 0),
         asthma10 = ifelse(dx10 %in% asthma_icd9, 1, 0),
         asthma11 = ifelse(dx11 %in% asthma_icd9, 1, 0),
         asthma12 = ifelse(dx12 %in% asthma_icd9, 1, 0),
         asthma13 = ifelse(dx13 %in% asthma_icd9, 1, 0),
         # sum up the asthma indicators
         asthma_sum = (asthma1 + asthma2 + asthma3 + asthma4 + asthma5 + asthma6 + asthma7 + asthma8 + asthma9 + asthma10 + asthma11 + asthma12 + asthma13),
         asthma_dx = ifelse(asthma_sum>0, asthma_sum, 0)
         ) %>% # end of mutate asthma
  mutate(copd1 = ifelse(dx1 %in% copd_icd9, 1, 0),
         copd2 = ifelse(dx2 %in% copd_icd9, 1, 0),
         copd3 = ifelse(dx3 %in% copd_icd9, 1, 0),
         copd4 = ifelse(dx4 %in% copd_icd9, 1, 0),
         copd5 = ifelse(dx5 %in% copd_icd9, 1, 0),
         copd6 = ifelse(dx6 %in% copd_icd9, 1, 0),
         copd7 = ifelse(dx7 %in% copd_icd9, 1, 0),
         copd8 = ifelse(dx8 %in% copd_icd9, 1, 0),
         copd9 = ifelse(dx9 %in% copd_icd9, 1, 0),
         copd10 = ifelse(dx10 %in% copd_icd9, 1, 0),
         copd11 = ifelse(dx11 %in% copd_icd9, 1, 0),
         copd12 = ifelse(dx12 %in% copd_icd9, 1, 0),
         copd13 = ifelse(dx13 %in% copd_icd9, 1, 0),
         # sum up the pneumonia indicators
         copd_sum = (copd1 + copd2 + copd3 + copd4 +copd5 + copd6 + copd7 + copd8 + copd9 +copd10 + copd11 + copd12 + copd13),
         copd_dx = ifelse(copd_sum>0, copd_sum, 0)
  ) #end of mutate of copd
  

or_ndc_check <- or_ndc_asthma_copd_sum %>%
  select(personkey, index, asthma_dx, copd_dx)
summary(as.factor(or_ndc_check$asthma_dx))

or_asthma <- or_ndc_asthma_copd_sum %>%
  filter(index=="asthma")
or_copd <- or_ndc_asthma_copd_sum %>%
  filter(index=="copd")
or_both <- or_ndc_asthma_copd_sum %>%
  filter(index=="both")
or_other <- or_ndc_asthma_copd_sum %>%
  filter(index=="other")

summary(as.factor(or_other$dx1))

## check for one sample
summary(as.factor(or_asthma$personkey))
summary(as.factor(or_copd$personkey))
summary(as.factor(or_both$personkey))
summary(as.factor(or_other$personkey))


or_asthma_sample <- or_asthma %>%
  filter(personkey == 10101244) 
which(or_asthma_sample$asthma_dx!=0)

or_copd_sample  <- or_copd %>%
  filter(personkey == 13564804) 

or_both_sample  <- or_both %>%
  filter(personkey == 12979399) 

or_other_sample  <- or_other %>%
  filter(personkey == 10289787) 


or_asthma_miss <- or_asthma %>%
  filter(dx1=="*NULL*" &
         dx2=="*NULL*" &
         dx3=="*NULL*" &
         dx4=="*NULL*" &
         dx5=="*NULL*" &
         dx6=="*NULL*" &
         dx7=="*NULL*" &
         dx8=="*NULL*" &
         dx9=="*NULL*" &
         dx10=="*NULL*" &
         dx11=="" &
         dx12=="" &
         dx13=="") %>%
  filter(ndc=="" |
         ndc=="*NULL*") # 89482 claims missing in asthma data set

or_copd_miss <- or_copd %>%
  filter(dx1=="*NULL*" &
         dx2=="*NULL*" &
         dx3=="*NULL*" &
         dx4=="*NULL*" &
         dx5=="*NULL*" &
         dx6=="*NULL*" &
         dx7=="*NULL*" &
         dx8=="*NULL*" &
         dx9=="*NULL*" &
         dx10=="*NULL*" &
         dx11=="" &
         dx12=="" &
         dx13=="") %>%
  filter(ndc=="" |
         ndc=="*NULL*") # 18941 claims missing in copd data set


or_both_miss <- or_both %>%
  filter(dx1=="*NULL*" &
         dx2=="*NULL*" &
         dx3=="*NULL*" &
         dx4=="*NULL*" &
         dx5=="*NULL*" &
         dx6=="*NULL*" &
         dx7=="*NULL*" &
         dx8=="*NULL*" &
         dx9=="*NULL*" &
         dx10=="*NULL*" &
         dx11=="" &
         dx12=="" &
         dx13=="") %>%
  filter(ndc=="" |
         ndc=="*NULL*") # 17963 claims missing in both data set


or_other_miss <- or_other %>%
  filter(dx1=="*NULL*" &
         dx2=="*NULL*" &
         dx3=="*NULL*" &
         dx4=="*NULL*" &
         dx5=="*NULL*" &
         dx6=="*NULL*" &
         dx7=="*NULL*" &
         dx8=="*NULL*" &
         dx9=="*NULL*" &
         dx10=="*NULL*" &
         dx11=="" &
         dx12=="" &
         dx13=="") %>%
  filter(ndc=="" |
         ndc=="*NULL*") # 46971 claims missing in other data set (5848 personkey)

or_other_not_miss <- or_other %>%
  filter(dx1!="*NULL*" |
         dx2!="*NULL*" |
         dx3!="*NULL*" |
         dx4!="*NULL*" |
         dx5!="*NULL*" |
         dx6!="*NULL*" |
         dx7!="*NULL*" |
         dx8!="*NULL*" |
         dx9!="*NULL*" |
         dx10!="*NULL*" |
         dx11!="" |
         dx12!="" |
         dx13!="" |
         ndc!="" |
         ndc!="*NULL*") # 20269 missing in total data set

length(unique(or_other_not_miss$personkey)) # [1] 27275

dim(or_asthma_miss)
dim(or_copd_miss)
dim(or_both_miss)
dim(or_other_miss)


sum(or_ndc_all_miss_id %in% unique(or_other$personkey))


write_path <- paste0('../../../data/data_new/',
                     'oregon_asthma_sample.csv')
write_csv(or_asthma_sample, write_path) 

write_path2 <- paste0('../../../data/data_new/',
                     'oregon_ndc_with_index.csv')

write_csv(or_ndc_asthma_copd_sum, write_path2)


```

```{r choose ndc, eval=FALSE, echo=FALSE}

# limit to the unique personkey different days' first visit
oregon_asthma_df <- oregon_asthma %>% 
  group_by(personkey) %>% 
  arrange(personkey, fromdate, line) %>% 
  mutate(num_visit = dense_rank(fromdate)) %>%
  arrange(personkey, num_visit) %>% 
  select(personkey, clmid, num_visit) %>% 
  unique() %>% 
  full_join(oregon_asthma, by = c("personkey", "clmid")) %>% 
  arrange(personkey, clmid, line, fromdate) %>% 
  filter(row_number() == 1) %>%
  # add new transverted from date
  mutate(dates = as.Date(fromdate, "%m/%d/%Y")) %>%
  filter(dates >= '2013-05-01' & 
         dates <= '2013-09-30') # 24538

write_path2 <- paste0("../../../data/data_new/oregon_asthma_ndc.csv")
write_csv(oregon_asthma_df, write_path2)

```

## Time-Stratified Case-Crossover (Population-Weighted PM~2.5~ Assigned by Zip Code)
*referents same day of week within fire season May - September*
 
Because we want the I also make the counterfactual dates for each claim, which means that for each claim, I choose the day the claim shows, to indicate the outcome for this day is "1". Then I make the dates week by week before this date, and after this date in the whole wildfire season, and indicate these dates' outcomes are "0". Then I can use these outcomes for the following model building.

```{r casecrossover, eval=FALSE, echo=FALSE}
### Casecrossover study
read_path3 <- paste0("../../../data/data_new/medication/oregon_asthma_ndc.csv")
oregon_asthma_df <- read_csv(read_path3)


outcome_id <- oregon_asthma_df %>%
  # arrange with dates
  arrange(dates) %>%
  mutate(id = seq(1, nrow(.), by = 1))

# create dataset to populate
id_date_df <- data_frame()


# begin second loop to create counterfactual observations for each case subject
for (k in 1:nrow(outcome_id)){
  
  # find the replicate times of weeks
  dates_l <- outcome_id[[k,74]] 
  n1 <- 0
  d=as.Date("2013-05-01")
  i=1
  while (dates_l >= "2013-05-01"){
    dates_l <- dates_l - 7
    d[i] = dates_l
    i = i+1
    n1 = n1+1
  }
  d[1:n1-1] # shows character(0) when the first week
  n1-1
  
  dates_l <- outcome_id[[k,74]] 
  n2=0
  e=as.Date("2013-09-30")
  j=1
  while (dates_l <= "2013-09-30"){
    dates_l <- dates_l + 7
    e[j]=dates_l
    j=j+1
    n2 = n2 + 1
  }
  e[1:n2-1] # shows character(0) when the last week
  n2-1
  
  # replicate covariates length of counterfactual dates
  # and make conuterfactual dates
  if (n1==1){
    cov_df <- do.call("bind_rows", replicate(n1+n2-1, outcome_id[k,],simplify = F))
    cov_df$dates <- c(outcome_id[[k,74]], e[1:n2-1])
  } else if (n2==1){
    cov_df <- do.call("bind_rows", replicate(n1+n2-1, outcome_id[k,],simplify = F))
    cov_df$dates <- c(outcome_id[[k,74]], d[1:(n1-1)])
  }else{
    cov_df <- do.call("bind_rows", replicate(n1+n2-1, outcome_id[k,],simplify = F))
    cov_df$dates <- c(outcome_id[[k,74]], d[1:(n1-1)], e[1:n2-1])
  }
  
  # bind unique id and date of the year with covariates
  id_date <- bind_cols(cov_df)
  # iteration which binds rows of unique ids
  id_date_df <- bind_rows(id_date_df, id_date)
}

outcome_casecross <- id_date_df %>%
  mutate(outcome = ifelse(dates == as.Date(fromdate, "%m/%d/%Y"), 1, 0)) %>%
  arrange(id, dates) # order by id and date

outcome_casecross <- id_date_df %>%
  mutate(outcome = ifelse(dates == as.Date(fromdate, "%m/%d/%Y"), 1, 0)) %>%
  arrange(personkey, dates) # order by id and date

write_path2 <- paste0("../../../data/data_new/oregon_ndc_casecrossover.csv")
write_csv(outcome_casecross, write_path2)

```

To get the time stratified data set, I create the lag variables that take smoke values from the previous days for zip codes, join the zipcode level populatoin-weighted pm to the data set, and create age, sex, month and season index.

```{r time stratified zip for casecrossover, eval=FALSE, echo=FALSE}
### Time stratified ------------------------------------------------------------
# read in zipcode level populatoin-weighted pm
read_path5 <- paste0('C:/Users/jyliu/Desktop/local_git_repo/oregon_wildfire_new/data/Oregon_PM/zip_pm_to_merge_with_acap.csv')

zip_smoke <- read_csv(read_path5) # 63801 rows

# descriptives of the two smoke datasets
summary(zip_smoke)

# Zipcode PM2.5 estimates
# create lag variables that take smoke values from n previous days for zipcodes
zip_smoke_w_lag <- zip_smoke %>% arrange(ZIPCODE, date) %>%
  # group by zipcode
  group_by(ZIPCODE) %>% 
  # wrf
  mutate(wrf_f_pm_lag1 = lag(wrf_f_pm, 1, order_by = ZIPCODE), 
         wrf_f_pm_lag2 = lag(wrf_f_pm, 2, order_by = ZIPCODE),
         wrf_f_pm_lag3 = lag(wrf_f_pm, 3, order_by = ZIPCODE),
         wrf_f_pm_lag4 = lag(wrf_f_pm, 4, order_by = ZIPCODE),
         wrf_f_pm_lag5 = lag(wrf_f_pm, 5, order_by = ZIPCODE),
         wrf_f_pm_lag6 = lag(wrf_f_pm, 6, order_by = ZIPCODE),
         wrf_f_pm_lag7 = lag(wrf_f_pm, 7, order_by = ZIPCODE),
         # wrf no fire lag
         wrf_nf_pm_lag1 = lag(wrf_nf_pm, 1, order_by = ZIPCODE),
         wrf_nf_pm_lag2 = lag(wrf_nf_pm, 2, order_by = ZIPCODE),
         wrf_nf_pm_lag3 = lag(wrf_nf_pm, 3, order_by = ZIPCODE),
         wrf_nf_pm_lag4 = lag(wrf_nf_pm, 4, order_by = ZIPCODE),
         wrf_nf_pm_lag5 = lag(wrf_nf_pm, 5, order_by = ZIPCODE),
         wrf_nf_pm_lag6 = lag(wrf_nf_pm, 6, order_by = ZIPCODE),
         wrf_nf_pm_lag7 = lag(wrf_nf_pm, 7, order_by = ZIPCODE),
         # wrf_smk_pm
         wrf_smk_pm_lag1 = lag(wrf_smk_pm, 1, order_by = ZIPCODE),
         wrf_smk_pm_lag2 = lag(wrf_smk_pm, 2, order_by = ZIPCODE),
         wrf_smk_pm_lag3 = lag(wrf_smk_pm, 3, order_by = ZIPCODE),
         wrf_smk_pm_lag4 = lag(wrf_smk_pm, 4, order_by = ZIPCODE),
         wrf_smk_pm_lag5 = lag(wrf_smk_pm, 5, order_by = ZIPCODE),
         wrf_smk_pm_lag6 = lag(wrf_smk_pm, 6, order_by = ZIPCODE),
         wrf_smk_pm_lag7 = lag(wrf_smk_pm, 7, order_by = ZIPCODE),
         # geo weighted pm
         geo_wt_pm_lag1 = lag(geo_wt_pm, 1, order_by = ZIPCODE),
         geo_wt_pm_lag2 = lag(geo_wt_pm, 2, order_by = ZIPCODE),
         geo_wt_pm_lag3 = lag(geo_wt_pm, 3, order_by = ZIPCODE),
         geo_wt_pm_lag4 = lag(geo_wt_pm, 4, order_by = ZIPCODE),
         geo_wt_pm_lag5 = lag(geo_wt_pm, 5, order_by = ZIPCODE),
         geo_wt_pm_lag6 = lag(geo_wt_pm, 6, order_by = ZIPCODE),
         geo_wt_pm_lag7 = lag(geo_wt_pm, 7, order_by = ZIPCODE),
         # krig pm
         krig_pm_lag1 = lag(krig_pm, 1, order_by = ZIPCODE),
         krig_pm_lag2 = lag(krig_pm, 2, order_by = ZIPCODE),
         krig_pm_lag3 = lag(krig_pm, 3, order_by = ZIPCODE),
         krig_pm_lag4 = lag(krig_pm, 4, order_by = ZIPCODE),
         krig_pm_lag5 = lag(krig_pm, 5, order_by = ZIPCODE), 
         krig_pm_lag6 = lag(krig_pm, 6, order_by = ZIPCODE),
         krig_pm_lag7 = lag(krig_pm, 7, order_by = ZIPCODE), 
         # background pm
         background_pm_lag1 = lag(background_pm, 1, order_by = ZIPCODE),
         background_pm_lag2 = lag(background_pm, 2, order_by = ZIPCODE),
         background_pm_lag3 = lag(background_pm, 3, order_by = ZIPCODE),
         background_pm_lag4 = lag(background_pm, 4, order_by = ZIPCODE),
         background_pm_lag5 = lag(background_pm, 5, order_by = ZIPCODE), 
         background_pm_lag6 = lag(background_pm, 6, order_by = ZIPCODE),
         background_pm_lag7 = lag(background_pm, 7, order_by = ZIPCODE), 
         # geo_smk_pm 
         geo_smk_pm_lag1 = lag(geo_smk_pm, 1, order_by = ZIPCODE),
         geo_smk_pm_lag2 = lag(geo_smk_pm, 2, order_by = ZIPCODE),
         geo_smk_pm_lag3 = lag(geo_smk_pm, 3, order_by = ZIPCODE),
         geo_smk_pm_lag4 = lag(geo_smk_pm, 4, order_by = ZIPCODE),
         geo_smk_pm_lag5 = lag(geo_smk_pm, 5, order_by = ZIPCODE),
         geo_smk_pm_lag6 = lag(geo_smk_pm, 6, order_by = ZIPCODE),
         geo_smk_pm_lag7 = lag(geo_smk_pm, 7, order_by = ZIPCODE),
         # krig smk pm
         krig_smk_pm_lag1 = lag(krig_smk_pm, 1, order_by = ZIPCODE),
         krig_smk_pm_lag2 = lag(krig_smk_pm, 2, order_by = ZIPCODE),
         krig_smk_pm_lag3 = lag(krig_smk_pm, 3, order_by = ZIPCODE),
         krig_smk_pm_lag4 = lag(krig_smk_pm, 4, order_by = ZIPCODE),
         krig_smk_pm_lag5 = lag(krig_smk_pm, 5, order_by = ZIPCODE),
         krig_smk_pm_lag6 = lag(krig_smk_pm, 6, order_by = ZIPCODE),
         krig_smk_pm_lag7 = lag(krig_smk_pm, 7, order_by = ZIPCODE),
         # temp
         wrf_temp_lag1 = lag(wrf_temp, 1, order_by = ZIPCODE),
         wrf_temp_lag2 = lag(wrf_temp, 2, order_by = ZIPCODE),
         wrf_temp_lag3 = lag(wrf_temp, 3, order_by = ZIPCODE),
         wrf_temp_lag4 = lag(wrf_temp, 4, order_by = ZIPCODE),
         wrf_temp_lag5 = lag(wrf_temp, 5, order_by = ZIPCODE), 
         wrf_temp_lag6 = lag(wrf_temp, 6, order_by = ZIPCODE),
         wrf_temp_lag7 = lag(wrf_temp, 7, order_by = ZIPCODE)) %>% 
  # ungroup by zip
  ungroup(ZIPCODE) %>% 
  # attach a zip indicator for each smoke variable
  setNames(paste(colnames(.), "zip", sep="_"))  %>% 
  # remove the '_zip' from the zipcode and date variable 
  rename(ZIPCODE = ZIPCODE_zip, date = date_zip)

read_path4 <- paste0("../data_new/medication/oregon_ndc_casecrossover.csv")
# read_path4 <- paste0("../../../data/data_new/oregon_ndc_casecrossover.csv") # for server
or_disease <- read_csv(read_path4)

### try join
colnames(or_disease)[24] <- c("ZIPCODE")
colnames(or_disease)[74] <- c("date")

outcome_casecross <- or_disease %>%
  # indicator for male=0, female=1, unknown = 2
  mutate(age = 2013-yob,
         sex_ind =ifelse(gender == "F", 1, 
                         ifelse(gender == "M", 0, 2)),
         age_ind = ifelse(age < 15, 0,
                          ifelse(age >= 15 & age < 65, 1,
                                 ifelse(age >= 65 & age <=105, 2, NA)))
  ) %>% # end of mutate 
  # create variables
  mutate(day = as.factor(weekdays(fromdate)),
         day_admit = as.factor(weekdays(date)),
         month_smk = month(fromdate),
         month_admit = month(date),
         season_smk = ifelse(fromdate >= "2013-03-20" &  
                               fromdate <= "2013-06-21", "spring",
                             ifelse(fromdate >= "2013-06-22" &  
                                      fromdate <= "2013-09-22", "summer",
                                    ifelse(fromdate >= "2013-09-23" & 
                                             fromdate <= "2013-12-21", "fall", "other"))),
         season_admit = ifelse(date >= "2013-03-20" &  
                                 date <= "2013-06-21", "spring",
                               ifelse(date >= "2013-06-22" &  
                                        date <= "2013-09-22", "summer",
                                      ifelse(date >= "2013-09-23" & 
                                               date <= "2013-12-21", "fall", "other")))) %>%
  # join with zip-level pm estimates
  left_join(zip_smoke_w_lag, by = c("date", "ZIPCODE"))%>%
  arrange(personkey, fromdate) # order by id and fromdate

write_path4 <- paste0("../data_new/medication/oregon_ndc_time_strat_casecrossover_zip.csv")
write_csv(outcome_casecross, write_path4)

```

## Time stratified for time series (Population-Weighted PM~2.5~ Assigned by County)

```{r time stratified county for ts, echo=FALSE, include=FALSE, eval=FALSE}
read_path7 <- paste0("../data_new/medication/oregon_asthma_ndc.csv")
or_ndc_claim <- read_csv(read_path7)

or_ndc_inhaler <- or_ndc_claim %>%
  select(personkey, num_visit, clmid, line, ZIP, dates) %>%
  rename(ZIPCODE = ZIP)


# Join data with names of Oregon counties 
oregon_fips <- read_csv('../instructions/oregon_FIPS.csv')
# remove the "County" character
# factor(oregon_fips$county)
oregon_fips$county <- gsub(" County", "", as.character(factor(oregon_fips$county)))

oregon_fips <- oregon_fips %>%
  mutate(st_county_fips = with(oregon_fips, paste0(st_code, fips)))

### Join county with zip
# read_path <- paste0('../data_new/update/or_zip_county_prop.csv') 
# or_zip_county <- read_csv(read_path)

read_path <- paste0('../instructions/oregon_zip_county.csv')
or_zip_county <- read_csv(read_path)

# or_zip_county$county_name[which(or_zip_county$county_name=="Hood.River")] <- "Hood River"

or_zip_county <- or_zip_county %>%
  select(zip, county_name) %>%
  rename(county = county_name) %>%
  rename(ZIPCODE = zip) %>%
  full_join(oregon_fips, by = "county") %>%
  select(ZIPCODE, county, state, st_county_fips) %>%
  rename(fips = st_county_fips) # 484

county_new <- c("Washington", "Douglas", "Lane", "Deschutes")

zip_new <- or_ndc_inhaler %>%
  filter(!(ZIPCODE %in% or_zip_county$ZIPCODE)) %>%
  select(ZIPCODE) %>%
  unique() %>%
  arrange(ZIPCODE) %>%
  mutate(county = county_new)

# summary(as.factor(zip_new$ZIPCODE))
# 97003 97471 97475 97703 
#    48   138     5    16 

or_zip_county_new <- or_zip_county %>%
  select(ZIPCODE, county) %>%
  bind_rows(zip_new)

write_path <- paste0("../data_new/county_data/zip_to_county_new.csv")
write_csv(or_zip_county_new, write_path)

read_path9 <- paste0("../data_new/county_data/or_census_pop_est_county.csv")
or_pop <- read_csv(read_path9)

or_pop <- or_pop %>%
  rename(county = GEO_display_label, pop = respop72013) %>%
  select(county, pop) 
or_pop$county <- gsub(" County, Oregon", "", as.character(factor(or_pop$county)))

### import county data
read_path_county_pm <- paste0('C:/Users/jyliu/Desktop/local_git_repo/oregon_wildfire_new/data_new/county_data/or_county_pop_wt_pm.csv')

county_smoke <- read_csv(read_path_county_pm) # 63801 rows

# descriptives of the two smoke datasets
summary(county_smoke)

county_smoke$county[which(county_smoke$county=="Hood.River")] <- "Hood River"

# Zipcode PM2.5 estimates
# create lag variables that take smoke values from n previous days for zipcodes
county_smoke_w_lag <- county_smoke %>% arrange(county, date) %>%
  # group by zipcode
  group_by(county) %>% 
  # wrf
  mutate(wrf_f_pm_lag1 = lag(wrf_pm, 1, order_by = county), 
         wrf_f_pm_lag2 = lag(wrf_pm, 2, order_by = county),
         wrf_f_pm_lag3 = lag(wrf_pm, 3, order_by = county),
         wrf_f_pm_lag4 = lag(wrf_pm, 4, order_by = county),
         wrf_f_pm_lag5 = lag(wrf_pm, 5, order_by = county),
         wrf_f_pm_lag6 = lag(wrf_pm, 6, order_by = county),
         wrf_f_pm_lag7 = lag(wrf_pm, 7, order_by = county),
         # wrf no fire lag
         wrf_nf_pm_lag1 = lag(wrf_nf_pm, 1, order_by = county),
         wrf_nf_pm_lag2 = lag(wrf_nf_pm, 2, order_by = county),
         wrf_nf_pm_lag3 = lag(wrf_nf_pm, 3, order_by = county),
         wrf_nf_pm_lag4 = lag(wrf_nf_pm, 4, order_by = county),
         wrf_nf_pm_lag5 = lag(wrf_nf_pm, 5, order_by = county),
         wrf_nf_pm_lag6 = lag(wrf_nf_pm, 6, order_by = county),
         wrf_nf_pm_lag7 = lag(wrf_nf_pm, 7, order_by = county),
         # wrf_smk_pm
         wrf_smk_pm_lag1 = lag(wrf_smk_pm, 1, order_by = county),
         wrf_smk_pm_lag2 = lag(wrf_smk_pm, 2, order_by = county),
         wrf_smk_pm_lag3 = lag(wrf_smk_pm, 3, order_by = county),
         wrf_smk_pm_lag4 = lag(wrf_smk_pm, 4, order_by = county),
         wrf_smk_pm_lag5 = lag(wrf_smk_pm, 5, order_by = county),
         wrf_smk_pm_lag6 = lag(wrf_smk_pm, 6, order_by = county),
         wrf_smk_pm_lag7 = lag(wrf_smk_pm, 7, order_by = county),
         # geo weighted pm
         geo_wt_pm_lag1 = lag(geo_wt_pm, 1, order_by = county),
         geo_wt_pm_lag2 = lag(geo_wt_pm, 2, order_by = county),
         geo_wt_pm_lag3 = lag(geo_wt_pm, 3, order_by = county),
         geo_wt_pm_lag4 = lag(geo_wt_pm, 4, order_by = county),
         geo_wt_pm_lag5 = lag(geo_wt_pm, 5, order_by = county),
         geo_wt_pm_lag6 = lag(geo_wt_pm, 6, order_by = county),
         geo_wt_pm_lag7 = lag(geo_wt_pm, 7, order_by = county),
         # krig pm
         krig_pm_lag1 = lag(krig_pm, 1, order_by = county),
         krig_pm_lag2 = lag(krig_pm, 2, order_by = county),
         krig_pm_lag3 = lag(krig_pm, 3, order_by = county),
         krig_pm_lag4 = lag(krig_pm, 4, order_by = county),
         krig_pm_lag5 = lag(krig_pm, 5, order_by = county), 
         krig_pm_lag6 = lag(krig_pm, 6, order_by = county),
         krig_pm_lag7 = lag(krig_pm, 7, order_by = county), 
         # background pm
         background_pm_lag1 = lag(background_pm, 1, order_by = county),
         background_pm_lag2 = lag(background_pm, 2, order_by = county),
         background_pm_lag3 = lag(background_pm, 3, order_by = county),
         background_pm_lag4 = lag(background_pm, 4, order_by = county),
         background_pm_lag5 = lag(background_pm, 5, order_by = county), 
         background_pm_lag6 = lag(background_pm, 6, order_by = county),
         background_pm_lag7 = lag(background_pm, 7, order_by = county), 
         # geo_smk_pm 
         geo_smk_pm_lag1 = lag(geo_smk_pm, 1, order_by = county),
         geo_smk_pm_lag2 = lag(geo_smk_pm, 2, order_by = county),
         geo_smk_pm_lag3 = lag(geo_smk_pm, 3, order_by = county),
         geo_smk_pm_lag4 = lag(geo_smk_pm, 4, order_by = county),
         geo_smk_pm_lag5 = lag(geo_smk_pm, 5, order_by = county),
         geo_smk_pm_lag6 = lag(geo_smk_pm, 6, order_by = county),
         geo_smk_pm_lag7 = lag(geo_smk_pm, 7, order_by = county),
         # krig smk pm
         krig_smk_pm_lag1 = lag(krig_smk_pm, 1, order_by = county),
         krig_smk_pm_lag2 = lag(krig_smk_pm, 2, order_by = county),
         krig_smk_pm_lag3 = lag(krig_smk_pm, 3, order_by = county),
         krig_smk_pm_lag4 = lag(krig_smk_pm, 4, order_by = county),
         krig_smk_pm_lag5 = lag(krig_smk_pm, 5, order_by = county),
         krig_smk_pm_lag6 = lag(krig_smk_pm, 6, order_by = county),
         krig_smk_pm_lag7 = lag(krig_smk_pm, 7, order_by = county),
         # temp
         wrf_temp_lag1 = lag(wrf_temp, 1, order_by = county),
         wrf_temp_lag2 = lag(wrf_temp, 2, order_by = county),
         wrf_temp_lag3 = lag(wrf_temp, 3, order_by = county),
         wrf_temp_lag4 = lag(wrf_temp, 4, order_by = county),
         wrf_temp_lag5 = lag(wrf_temp, 5, order_by = county), 
         wrf_temp_lag6 = lag(wrf_temp, 6, order_by = county),
         wrf_temp_lag7 = lag(wrf_temp, 7, order_by = county)) %>% 
  # ungroup by zip
  ungroup(county) %>% 
  # attach a zip indicator for each smoke variable
  setNames(paste(colnames(.), "county", sep="_"))  %>% 
  # remove the '_zip' from the zipcode and date variable 
  rename(county = county_county, date = date_county, fips = fips_county) %>%
  select(-1)

or_ndc_county_ts <- or_ndc_inhaler %>%
  rename(date = dates) %>%
  mutate(day = ifelse(weekdays(date) == "Monday" |
                      weekdays(date) == "Tuesday" |
                      weekdays(date) == "Wednesday"|
                      weekdays(date) == "Thursday"|
                      weekdays(date) == "Friday", "weekday",
               ifelse(weekdays(date) == "Saturday" |
                      weekdays(date) == "Sunday", "weekend", NA))) %>%
  # join with county-level population
  left_join(or_zip_county_new, by = "ZIPCODE") %>% # 321 missing 
  filter(!is.na(county)) %>% # no missing value
  left_join(or_pop, by = "county") %>%
  left_join(county_smoke_w_lag, by = c("date", "county")) %>%
  arrange(personkey, date) %>% # order by id and fromdate
  group_by(county, date) %>% 
  # sum up each primary diagnosis for each outcome for each day for each county
  summarise(n_obs = n()) %>% 
  # join daily county estimates of pm2.5
  left_join(county_smoke_w_lag, by = c('date', 'county')) 

# summary(as.factor(or_ndc_county_ts$county)) 

or_ndc_county_ts <- or_ndc_county_ts %>%
  left_join(or_pop, by = "county") %>%
  mutate(geo_smk_pm10 = geo_smk_pm_county/10) %>%
  mutate(rate_per_100k = (n_obs/pop)*100000) %>%
  mutate(day = ifelse(weekdays(date) == "Monday" |
                      weekdays(date) == "Tuesday" |
                      weekdays(date) == "Wednesday"|
                      weekdays(date) == "Thursday"|
                      weekdays(date) == "Friday", "weekday",
               ifelse(weekdays(date) == "Saturday" |
                      weekdays(date) == "Sunday", "weekend", NA)))

or_ndc_county_ts$day[which(or_ndc_county_ts$date=="2013-05-27")] <- "weekend"
or_ndc_county_ts$day[which(or_ndc_county_ts$date=="2013-07-04")] <- "weekend"
or_ndc_county_ts$day[which(or_ndc_county_ts$date=="2013-09-02")] <- "weekend"                           

write_path5 <- paste0("../data_new/medication/or_ndc_county_time_series.csv")
write_csv(or_ndc_county_ts, write_path5)

```


### Descriptives

For all of 2013, there were a total of millons of all claims records in the APAC dataset. During the May 1st to September 30th wildfire season in Oregon state, there were 24217 pharmacy visits for the ndc of beta 2 agonists. The number of cases, as well as age-specific and sex-specific strate are shown below.

```{r descriptive table, echo = F, message = F, warning = F, results='asis'}
read_path6 <- paste0("../data_new/medication/oregon_ndc_time_strat_casecrossover_zip.csv")
inhaler_ndc <- read_csv(read_path6)
# asthma_ndc <- fread(read_path6, showProgress = T) # faster, but seems error in overall plot analysis

# dataframe list
method_list <- c('WRF-Chem Smoke', 'Geo-Weighted Smoke', 'Kriging Smoke')

# dataframe to loop through
inhaler_ndc_df <- data.frame(inhaler_ndc)

# outcome name
outcome_name <- "Inhalers"

# dataframe for analysis creation
# bind columns back together 
df_analysis <- inhaler_ndc_df %>%
  filter(!is.na(wrf_smk_pm_zip)) %>% 
  # only look at outcomes
  filter(outcome == 1) %>%
  # add another row that makes sure there is a person <15 in the dataframe
  # tricking xtabs to produce a 0 cell for the outcome for age <15
  add_row(outcome = 0, age_ind = 0)
  
# cross tabs
outcome_n <- xtabs(~ outcome, df_analysis)
cross_tab_age <- xtabs(~ outcome + age_ind, df_analysis)
cross_tab_sex <- xtabs(~ outcome + sex_ind, df_analysis)
# empty matrix
point_estimates <- matrix(nrow = 1, ncol = 7, byrow = T)
  
colnames(point_estimates) <- c("outcome", "n", "age_15", "age_15_65", 
                               "age_65", "female", "male")
  
# fill in the outcome name for the dataframe before the loop
point_estimates[, 1] <- outcome_name
# fill n
point_estimates[, 2] <- outcome_n[2] # second element of the 1 dimension vector
# age <15
point_estimates[, 3] <- cross_tab_age[2, 1]
# age 15 to 65
point_estimates[, 4] <- cross_tab_age[2, 2]
# age >65
point_estimates[, 5] <- cross_tab_age[2, 3]
# male == 0
point_estimates[, 7] <- cross_tab_sex[1, 1]
# female == 1
point_estimates[, 6] <- cross_tab_sex[1, 2]


# save point estimates as a dataframe
point_est_df <- as_data_frame(point_estimates)
  
# combine each outcome dataframe itteration in to a big dataset
asthma_point_est_df <- point_est_df %>% 
  # find proportions/percents for each strata in a row
  mutate(age_15_pr = as.character(round((as.numeric(age_15)/as.numeric(n))*100,1)),
         age_15_65_pr = as.character(round((as.numeric(age_15_65)/as.numeric(n))*100,1)),
         age_65_pr = as.character(round((as.numeric(age_65)/as.numeric(n))*100,1)),
         female_pr = as.character(round((as.numeric(female)/as.numeric(n))*100,1)),
         male_pr = as.character(round((as.numeric(male)/as.numeric(n))*100,1))) %>% 
  select(outcome, n, age_15, age_15_pr, age_15_65, age_15_65_pr, age_65,
         age_65_pr, female, female_pr, male, male_pr)

# str(asthma_point_est_df)
  
tab <- htmlTable(txtRound(asthma_point_est_df, digits = 1), 
           caption = "Number of cases for each outcome observed from May 1st to September 30st, 2013",
           # column headers
           header = c("Outcome", "Cases n", "Less than 15", "(%)", "15 to 65", "(%)", "Greater than 65",
                      "(%)", "Female", "(%)", "Male", "(%)"),
           # column spanner
           cgroup = c("","Age Category", "Sex"), 
           n.cgroup = c(2, 6, 4),
           padding.rgroup = "&nbsp;&nbsp;",
           css.cell = "padding-left: 0.5em; padding-right: .5em;", # cell space
           align = "llccccc" # column alignment,
            ) # end table

print(tab)


```


### Overall plot

```{r overall, warning =F, echo = F, results='asis'} 
# dataframe list

method_list <- c('WRF-Chem Smoke', 'Kriging Smoke', 'Geo-Weighted Smoke')

# dataframe to loop through
inhaler_ndc_df <- data.frame(inhaler_ndc)

# outcome name
outcome <- "Asthma Inhalers"
outcome_name <- "Asthma Inhalers"

# data wrangling ----
# Producing conditional logit model estimates loop 

# extract covariates from dataframe
covariates_df <- inhaler_ndc_df[, c(1:26, 74:84)]
  
# extract pm values and divide by 10 and ordered
#which(colnames(df_to_loop)=="global_smk_pm_zip") # code to find column numbers
pm_estimates_df <- inhaler_ndc_df[, c(87, 92, 91, 93)]/10  # create 10 unit increases

# new loop for age categories

# empty matrix (12 x 10 matrix)
point_estimates <- matrix(nrow = 3, ncol = 9, byrow = T)
    
colnames(point_estimates) <- c('outcome', 'pm_method', 'n', 'n_events', 
                                   'odds_ratio', 'lower95', 'upper95', 'se', 'p_val')    
  
# fill in the outcome namedataframe before method loop
point_estimates[, 1] <- outcome_name

# dataframe for analysis creation
# bind columns back together 
df_analysis <- cbind(covariates_df, pm_estimates_df) %>% 
  # remove missing pm values
  filter(!is.na(wrf_smk_pm_zip)) %>% 
  # the following code makes sure that the counterfactual values retained are 
  # symetric in that number of obs before = number of obs after
  mutate(obs_diff_admission = (fromdate - date)/7) 
  # dataframe is already for the entire fire season, so I don't need to subset anymore
  
# second loop to run a model for each pm estimation method
for(j in 38:40){

  # variable to model 
  var_name <- colnames(df_analysis[j])
      
  # set row number to fill
  row_n <- j-37
      
  # only run the model if the dataframe has observations
  if(nrow(df_analysis) != 0){
  # conditional logistic regression model
  mod <- clogit(outcome ~ df_analysis[[j]] + wrf_temp_zip + strata(personkey), df_analysis)
      
  # populate matrix
  point_estimates[row_n, 2] <- method_list[row_n]
  point_estimates[row_n, 3] <- mod$n
  point_estimates[row_n, 4] <- mod$nevent
  # odds ratio
  point_estimates[row_n, 5] <- round(exp(summary(mod)$coefficient[1,1]), 3)

  # 95% lower bound
  point_estimates[row_n, 6] <- round(exp((summary(mod)$coefficient[1,1]) -                                                                             1.96*(summary(mod)$coefficient[1,3])), 3)
  # 95% upper bound
  point_estimates[row_n, 7] <- round(exp((summary(mod)$coefficient[1,1]) +
                                        1.96*(summary(mod)$coefficient[1,3])), 3)
  # standard error
  point_estimates[row_n, 8] <- round(summary(mod)$coefficient[1,3], 4)
  # p val
  point_estimates[row_n, 9] <- round(summary(mod)$coefficient[1,5], 4)
      
  # create else statement that fills matrix with missing so I still have the row
  # in the final dataframe
  } else {point_estimates[row_n, 2] <- method_list[row_n]
          point_estimates[row_n, 3] <- 0
          point_estimates[row_n, 4] <- 0
          point_estimates[row_n, c(5:9)] <- 99 } # end 'if else' statement
  } # end methods loop
  
# save point estimates as a dataframe
combined_point_est_df <- as_data_frame(point_estimates)



wrf_geo_age <- combined_point_est_df %>% 
  # filter columns to just geo-smk
  # filter(pm_method == "GWR Smoke" |
    #      pm_method == "WRF-Chem Smoke") %>% 
  # subset columns I want to put in to the table
  select(2, 4:7) %>% 
  mutate(odds_ratio = ifelse(odds_ratio == 99, "--", odds_ratio),
         lower95 = ifelse(lower95 == 99, "--", lower95),
         upper95 = ifelse(upper95 == 99, "--", upper95))


tab <- htmlTable(txtRound(wrf_geo_age, digits = 3, 1:3), 
         caption = "Association between a 10 ug/m^3 in PM2.5 three smoke method and pharmacy outcomes",
         # row group by outcome
         rgroup = "Asthma Inhalers",
         n.rgroup = c(rep(3, 1)), # 6 rows for each age cat for each outcome
         # column headers
         header = c("Est Method", "Events",
                    "OR&dagger;", "Lower", "Upper"),
         # column spanner
         cgroup = c("", "95% CI"), 
         n.cgroup = c(3, 2),
         padding.rgroup = "&nbsp;&nbsp;",
         css.cell = "padding-left: 0.5em; padding-right: .5em;", # cell space
         align = "llcccc", # column alignment,
         tfoot="&dagger; Referent periods matched to events on same day of week within May to September fire season."
         ) # end table
  
print(tab)
  
combined_point_est_df_new <- combined_point_est_df %>%
  mutate(n_events_new = ifelse(as.numeric(n_events)>=100, n_events,
                        ifelse(as.numeric(n_events)<100, "0", NA))) %>%
  select(-n_events) %>%
  rename(n_events = n_events_new)


# ggplot of odds ratios, facet wrapped by outcomes -----
# convert variables from character to either numeric or factor
# factor preserves the order of the variable
wrf_geo_age_plot <- combined_point_est_df_new %>% 
  # filter columns to just geo-smk
 #  filter(pm_method == "GWR Smoke" | pm_method == "WRF-Chem Smoke") %>% 
  # do not plot results with less than 15 events, create missing vals
  # in mutate
  mutate(odds_ratio = ifelse(as.numeric(n_events) < 15, 
                             99, odds_ratio),
         lower95 = ifelse(as.numeric(n_events) < 15, 
                             99, lower95),
         upper95 = ifelse(as.numeric(n_events) < 15, 
                             99, upper95)) %>% 
  # subset columns I want to put in to the table
  select(1, 2, 9, 4:6) %>% 
  mutate(odds_ratio = ifelse(odds_ratio == 99, NA, odds_ratio),
         lower95 = ifelse(lower95 == 99, NA, lower95),
         upper95 = ifelse(upper95 == 99, NA, upper95))

# change characters to numeric and factor  
wrf_geo_age_plot$outcome <- factor(wrf_geo_age_plot$outcome,
                              levels = unique(wrf_geo_age_plot$outcome))

wrf_geo_age_plot$pm_method <- factor(wrf_geo_age_plot$pm_method,
                                levels = unique(wrf_geo_age_plot$pm_method))

wrf_geo_age_plot$n_events <- as.numeric(wrf_geo_age_plot$n_events)
wrf_geo_age_plot$odds_ratio <- as.numeric(wrf_geo_age_plot$odds_ratio)
wrf_geo_age_plot$lower95 <- as.numeric(wrf_geo_age_plot$lower95)
wrf_geo_age_plot$upper95 <- as.numeric(wrf_geo_age_plot$upper95)


## ggplot 
  print_plot <- ggplot(wrf_geo_age_plot,
    aes(x = pm_method, y = odds_ratio, color = pm_method), na.rm = T) +
    geom_point(position = position_dodge(width = 0.5), na.rm = T) + 
    geom_errorbar(aes(ymin=lower95, ymax=upper95), 
                  position = position_dodge(width = 0.5), width = 0.2, na.rm =T) +
    # custom color 
    scale_color_manual(name = "Smoke-Estimation Method", 
                       values = c("red",  "blue", "#32115C"),
                       guide = guide_legend(title.position = "top", title.hjust = 0.5)) +
    facet_wrap(~outcome, nrow = 3, scales = "free") +
    geom_hline(yintercept = 1, linetype=2) +
    #ggtitle('Association Between PM2.5 from \n Wildfire Smoke on Hospitalizations') +
    ylab(expression(paste("Odds Ratio for 10g/m"^3, " Increase in PM"[2.5]))) +
    #ylim(0, 2) +
    xlab('Smoke Estimation Method') +
    # plot theme
    theme(panel.background = element_rect(fill = 'white', colour = 'black'),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    # strip element
    strip.background = element_rect(colour=NA, fill=NA),
    panel.border = element_rect(fill = NA, color = "black"),
    # facet text size
    strip.text = element_text(size = 10),
    # axis element
    #axis.text.x = element_blank(),
    #axis.title.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.title.y = element_text(angle = 90),
    # legend elements
    legend.position = "bottom")
    #legend.text = element_text(size = 8))


  print(print_plot)
  # save figure
  ggsave("../plot_new/ndc_overall_three.pdf", plot = print_plot, 
       width = 12, height = 8, units = "in")
  
```


### Time-Stratified by Age Categories 

Following table and figure look at some outcomes stratified by age category. 

For some outcomes, such like Age > 65 in WRF-Chem method, the CI is the only insignificant one in the plot.


```{r time stratified age strata cdc met, warning =F, echo = F, results='asis'} 
# dataframe list

method_list <- c('WRF-Chem Smoke', 'Kriging Smoke', 'Geo-Weighted Smoke')

# dataframe to loop through
inhaler_ndc_df <- data.frame(inhaler_ndc)

# outcome name
outcome <- "asthma inhalers"
outcome_name <- "Asthma inhalers"

# age category list
age_cat_list <- c(0,1,2)

# create an empty list to row bind dataframes together
datalist1 <- list()


# data wrangling ----
# Producing conditional logit model estimates loop 

# extract covariates from dataframe
covariates_df <- inhaler_ndc_df[, c(1:26, 74:84)]
  
# extract pm values and divide by 10 and ordered
#which(colnames(df_to_loop)=="global_smk_pm_zip") # code to find column numbers
pm_estimates_df <- inhaler_ndc_df[, c(87, 92, 91, 93)]/10  # create 10 unit increases

# new loop for age categories
for(k in 0:2){
  # empty matrix (12 x 10 matrix)
  point_estimates <- matrix(nrow = 3, ncol = 10, byrow = T)
    
  colnames(point_estimates) <- c('outcome', 'age_cat', 'pm_method', 'n', 'n_events', 
                                   'odds_ratio', 'lower95', 'upper95', 'se', 'p_val')    
  
  # fill in the outcome namedataframe before method loop
  point_estimates[, 1] <- outcome_name
  # repeat the age category 4 times for each pm method
  point_estimates[, 2] <- k
    
  # dataframe for analysis creation
  # bind columns back together 
  df_analysis <- cbind(covariates_df, pm_estimates_df) %>% 
    # remove missing pm values
    filter(!is.na(wrf_smk_pm_zip)) %>% 
    # limit to specific age category
    filter(age_ind == k) %>% 
    # the following code makes sure that the counterfactual values retained are 
    # symetric in that number of obs before = number of obs after
    mutate(obs_diff_admission = (fromdate - date)/7) 
    # dataframe is already for the entire fire season, so I don't need to subset anymore
  
  # second loop to run a model for each pm estimation method
  for(j in 38:40){

    # variable to model 
    var_name <- colnames(df_analysis[j])
      
    # set row number to fill
    row_n <- j-37
      
    # only run the model if the dataframe has observations
    if(nrow(df_analysis) != 0){
    # conditional logistic regression model
    mod <- clogit(outcome ~ df_analysis[[j]] + wrf_temp_zip + strata(personkey), df_analysis)
      
    # populate matrix
    point_estimates[row_n, 3] <- method_list[row_n]
    point_estimates[row_n, 4] <- mod$n
    point_estimates[row_n, 5] <- mod$nevent
    # odds ratio
    point_estimates[row_n, 6] <- round(exp(summary(mod)$coefficient[1,1]), 3)

    # 95% lower bound
    point_estimates[row_n, 7] <- round(exp((summary(mod)$coefficient[1,1]) -                                                                             1.96*(summary(mod)$coefficient[1,3])), 3)
    # 95% upper bound
    point_estimates[row_n, 8] <- round(exp((summary(mod)$coefficient[1,1]) +
                                        1.96*(summary(mod)$coefficient[1,3])), 3)
    # standard error
    point_estimates[row_n, 9] <- round(summary(mod)$coefficient[1,3], 4)
    # p val
    point_estimates[row_n, 10] <- round(summary(mod)$coefficient[1,5], 4)
      
    # create else statement that fills matrix with missing so I still have the row
    # in the final dataframe
    } else {point_estimates[row_n, 3] <- method_list[row_n]
            point_estimates[row_n, 4] <- 0
            point_estimates[row_n, 5] <- 0
            point_estimates[row_n, c(6:10)] <- 99 } # end 'if else' statement
    } # end methods loop
  
  # save point estimates as a dataframe
  point_est_df <- as_data_frame(point_estimates)
  datalist1[[k+1]] <- point_est_df
} # end age category loop

# bind rows of age category estimates together
combined_point_est_df <- bind_rows(datalist1)



wrf_geo_age <- combined_point_est_df %>% 
  # filter columns to just geo-smk
  # filter(pm_method == "GWR Smoke" |
    #      pm_method == "WRF-Chem Smoke") %>% 
  mutate(age_cat2 = ifelse(age_cat == 0, "Less than 15", 
                    ifelse(age_cat == 1, "15-65",
                    ifelse(age_cat == 2, "Greater than 65", NA)))) %>% 
  # subset columns I want to put in to the table
  select(3, 11, 5:8) %>% 
  mutate(odds_ratio = ifelse(odds_ratio == 99, "--", odds_ratio),
         lower95 = ifelse(lower95 == 99, "--", lower95),
         upper95 = ifelse(upper95 == 99, "--", upper95))


tab <- htmlTable(txtRound(wrf_geo_age, digits = 3, 1:3), 
         caption = "Association between a 10 ug/m^3 in PM2.5 geo smoke and health outcomes stratified by age",
         # row group by outcome
         rgroup = "Asthma inhalers",
         n.rgroup = c(rep(9, 1)), # 6 rows for each age cat for each outcome
         # column headers
         header = c("Est Method", "Age Group", "Events",
                    "OR&dagger;", "Lower", "Upper"),
         # column spanner
         cgroup = c("", "95% CI"), 
         n.cgroup = c(4, 2),
         padding.rgroup = "&nbsp;&nbsp;",
         css.cell = "padding-left: 0.5em; padding-right: .5em;", # cell space
         align = "llcccc", # column alignment,
         tfoot="&dagger; Time-stratified: referent periods matched to events on same day of week within May to September fire season."
         ) # end table
  
print(tab)
  
combined_point_est_df_new <- combined_point_est_df %>%
  mutate(n_events_new = ifelse(as.numeric(n_events)>=100, n_events,
                        ifelse(as.numeric(n_events)<100, "0", NA))) %>%
  select(-n_events) %>%
  rename(n_events = n_events_new)


# ggplot of odds ratios, facet wrapped by outcomes -----
# convert variables from character to either numeric or factor
# factor preserves the order of the variable
wrf_geo_age_plot <- combined_point_est_df_new %>% 
  # filter columns to just geo-smk
 #  filter(pm_method == "GWR Smoke" | pm_method == "WRF-Chem Smoke") %>% 
  # do not plot results with less than 15 events, create missing vals
  # in mutate
  mutate(odds_ratio = ifelse(as.numeric(n_events) < 15, 
                             99, odds_ratio),
         lower95 = ifelse(as.numeric(n_events) < 15, 
                             99, lower95),
         upper95 = ifelse(as.numeric(n_events) < 15, 
                             99, upper95),
         age_cat2 = ifelse(age_cat == 0, "<15", 
                    ifelse(age_cat == 1, "15-65",
                    ifelse(age_cat == 2, ">65", NA)))) %>% 
  # subset columns I want to put in to the table
  select(1, 3, 11, 10, 5:7) %>% 
  mutate(odds_ratio = ifelse(odds_ratio == 99, NA, odds_ratio),
         lower95 = ifelse(lower95 == 99, NA, lower95),
         upper95 = ifelse(upper95 == 99, NA, upper95))

# change characters to numeric and factor  
wrf_geo_age_plot$outcome <- factor(wrf_geo_age_plot$outcome,
                              levels = unique(wrf_geo_age_plot$outcome))

wrf_geo_age_plot$pm_method <- factor(wrf_geo_age_plot$pm_method,
                                levels = unique(wrf_geo_age_plot$pm_method))

wrf_geo_age_plot$age_cat2 <- factor(wrf_geo_age_plot$age_cat2,
                                levels = unique(wrf_geo_age_plot$age_cat2))

wrf_geo_age_plot$n_events <- as.numeric(wrf_geo_age_plot$n_events)
wrf_geo_age_plot$odds_ratio <- as.numeric(wrf_geo_age_plot$odds_ratio)
wrf_geo_age_plot$lower95 <- as.numeric(wrf_geo_age_plot$lower95)
wrf_geo_age_plot$upper95 <- as.numeric(wrf_geo_age_plot$upper95)


## ggplot 
  print_plot <- ggplot(wrf_geo_age_plot,
    aes(x = age_cat2, y = odds_ratio, color = pm_method), na.rm = T) +
    geom_point(position = position_dodge(width = 0.5), na.rm = T) + 
    geom_errorbar(aes(ymin=lower95, ymax=upper95), 
                  position = position_dodge(width = 0.5), width = 0.2, na.rm =T) +
    # custom color 
    scale_color_manual(name = "Smoke-Estimation Method", 
                       values = c("red",  "blue", "#32115C"),
                       guide = guide_legend(title.position = "top", title.hjust = 0.5)) +
    facet_wrap(~outcome, nrow = 3, scales = "free") +
    geom_hline(yintercept = 1, linetype=2) +
    #ggtitle('Association Between PM2.5 from \n Wildfire Smoke on Hospitalizations') +
    ylab(expression(paste("Odds Ratio for 10g/m"^3, " Increase in PM"[2.5]))) +
    #ylim(0, 2) +
    xlab('Age Category ') +
    # plot theme
    theme(panel.background = element_rect(fill = 'white', colour = 'black'),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    # strip element
    strip.background = element_rect(colour=NA, fill=NA),
    panel.border = element_rect(fill = NA, color = "black"),
    # facet text size
    strip.text = element_text(size = 10), 
    # axis element
    #axis.text.x = element_blank(),
    #axis.title.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.title.y = element_text(angle = 90),
    # legend elements
    legend.position = "bottom")
    #legend.text = element_text(size = 8))


  print(print_plot)
  # save figure
  ggsave("../plot_new/ndc_age_fig_three.pdf", plot = print_plot, 
       width = 12, height = 8, units = "in")
  
```


### Seasonal Time-Stratified by Sex

Association with smoke PM~2.5~ and health outcomes stratified by sex. 

All the CI do not include 1, which means the use of asthma medication (beta 2 agonists) increases about 5% when smoke increase 10 units. So the risk for getting asthma will increase about 5% ~ 8% when the smoke PM2.5 increase 10 units.

```{r sex strata cdc met adj, warning = F, echo = F, results='asis'} 
method_list <- c('WRF-Chem Smoke', 'Kriging Smoke', 'Geo-Weighted Smoke')

# dataframe to loop through
inhaler_ndc_df <- data.frame(inhaler_ndc)

# outcome name
outcome <- "asthma inhalers"
outcome_name <- "Asthma inhalers"

# create an empty list to row bind dataframes together
datalist1 <- list()

# sex category list
sex_strata_list <- c(0,1)

# data wrangling ----
# Producing conditional logit model estimates loop 

# extract covariates from dataframe
covariates_df <- inhaler_ndc_df[, c(1:26, 74:84)]
  
# extract pm values and divide by 10 and ordered
#which(colnames(df_to_loop)=="global_smk_pm_zip") # code to find column numbers
pm_estimates_df <- inhaler_ndc_df[, c(87, 92, 91, 93)]/10  # create 10 unit increases


# new loop for sex categories
for(k in 0:1){
 
  # empty matrix (12 x 10 matrix)
  point_estimates <- matrix(nrow = 3, ncol = 10, byrow = T)
    
  colnames(point_estimates) <- c('outcome', 'sex', 'pm_method', 'n', 'n_events', 
                                   'odds_ratio', 'lower95', 'upper95', 'se', 'p_val')
    
  # fill in the outcome namedataframe before method loop
  point_estimates[, 1] <- outcome_name
  # repeat the sex category 4 times for each pm method
  point_estimates[, 2] <- k
    
    
  # dataframe for analysis creation
  # bind columns back together 
  df_analysis <- cbind(covariates_df, pm_estimates_df) %>% 
    # remove missing pm values
    filter(!is.na(wrf_smk_pm_zip)) %>% 
    # limit to specific sex category
    filter(sex_ind == k) %>% 
    # the following code makes sure that the counterfactual values retained are 
    # symetric in that number of obs before = number of obs after
    mutate(obs_diff_admission = (fromdate - date)/7) 
    # dataframe is already for the entire fire season, so I don't need to subset anymore
  
  # second loop to run a model for each pm estimation method
  for(j in 38:40){

    # variable to model 
    var_name <- colnames(df_analysis[j])
      
    # set row number to fill
    row_n <- j-37
      
    # only run the model if the dataframe has observations
    if(nrow(df_analysis) != 0){
    # conditional logistic regression model
    mod <- clogit(outcome ~ df_analysis[[j]] + wrf_temp_zip + strata(personkey), df_analysis)
      
    # populate matrix
    point_estimates[row_n, 3] <- method_list[row_n]
    point_estimates[row_n, 4] <- mod$n
    point_estimates[row_n, 5] <- mod$nevent
    # odds ratio
    point_estimates[row_n, 6] <- round(exp(summary(mod)$coefficient[1,1]), 3)

    # 95% lower bound
    point_estimates[row_n, 7] <- round(exp((summary(mod)$coefficient[1,1]) -
                                      1.96*(summary(mod)$coefficient[1,3])), 3)
    # 95% upper bound
    point_estimates[row_n, 8] <- round(exp((summary(mod)$coefficient[1,1]) +
                                      1.96*(summary(mod)$coefficient[1,3])), 3)
    # standard error
    point_estimates[row_n, 9] <- round(summary(mod)$coefficient[1,3], 4)
    # p val
    point_estimates[row_n, 10] <- round(summary(mod)$coefficient[1,5], 4)
      
    # create else statement that fills matrix with missing so I still have the row
    # in the final dataframe
    } else {point_estimates[row_n, 3] <- method_list[row_n]
            point_estimates[row_n, 4] <- 0
            point_estimates[row_n, 5] <- 0
            point_estimates[row_n, c(6:10)] <- 99 } # end 'if else' statement
    } # end methods loop
  
  # save point estimates as a dataframe
  point_est_df <- as_data_frame(point_estimates)
    
  # combine previous values in dataframe that has all outcome/methods comparisons
  datalist1[[k+1]] <- point_est_df
} # end sex category loop

# bind rows of sex category estimates together
combined_point_est_df <- bind_rows(datalist1)



wrf_geo_sex <- combined_point_est_df %>% 
  # filter columns to just geo-smk
  # filter(pm_method == "GWR Smoke" | pm_method == "WRF-Chem Smoke") %>% 
  mutate(sex_cat = ifelse(sex == 0, "Male", 
               ifelse(sex == 1, "Female", NA))) %>% 
  # subset columns I want to put in to the table
  select(3, 11, 5:8)%>% 
  mutate(odds_ratio = ifelse(odds_ratio == 99, "--", odds_ratio),
         lower95 = ifelse(lower95 == 99, "--", lower95),
         upper95 = ifelse(upper95 == 99, "--", upper95))


  tab <- htmlTable(txtRound(wrf_geo_sex, digits = 3, 1:3), 
           caption = "Association between a 10 ug/m^3 in PM2.5 geo smoke and pharmacy outcomes stratified by sex",
           # row group by outcome
           rgroup = "Asthma inhalers",
           n.rgroup = c(rep(6, 1)), # 2 rows for each sex strata for each outcome
           # column headers
           header = c("Est Method", "Sex Strata", "Events",
                      "OR&dagger;", "Lower", "Upper"),
           # column spanner
           cgroup = c("", "95% CI"), 
           n.cgroup = c(4, 2),
           padding.rgroup = "&nbsp;&nbsp;",
           css.cell = "padding-left: 0.5em; padding-right: .5em;", # cell space
           align = "llcccc", # column alignment,
           tfoot="&dagger; Time-stratified: referent periods matched to events on same day of week within July to October fire season."
            ) # end table
  
  print(tab)
 
# ggplot of odds ratios, facet wrapped by outcomes -----
# convert variables from character to either numeric or factor
# factor preserves the order of the variable
wrf_geo_sex_plot <- combined_point_est_df %>% 
  # filter columns to just geo-smk
 #  filter(pm_method == "GWR Smoke" | 
   #       pm_method == "WRF-Chem Smoke") %>% 
  mutate(sex_cat = ifelse(sex == 0, "Male", 
               ifelse(sex == 1, "Female", NA))) %>%
  # subset columns I want to put in to the table
  select(1, 3, 11, 5:8) %>% 
  mutate(odds_ratio = ifelse(odds_ratio == 99, NA, odds_ratio),
         lower95 = ifelse(lower95 == 99, NA, lower95),
         upper95 = ifelse(upper95 == 99, NA, upper95))  

# change characters to numeric and factor  
wrf_geo_sex_plot$outcome <- factor(wrf_geo_sex_plot$outcome,
                              levels = unique(wrf_geo_sex_plot$outcome))

wrf_geo_sex_plot$pm_method <- factor(wrf_geo_sex_plot$pm_method,
                                levels = unique(wrf_geo_sex_plot$pm_method))

wrf_geo_sex_plot$sex_cat <- factor(wrf_geo_sex_plot$sex_cat,
                                levels = unique(wrf_geo_sex_plot$sex_cat))

wrf_geo_sex_plot$n_events <- as.numeric(wrf_geo_sex_plot$n_events)
wrf_geo_sex_plot$odds_ratio <- as.numeric(wrf_geo_sex_plot$odds_ratio)
wrf_geo_sex_plot$lower95 <- as.numeric(wrf_geo_sex_plot$lower95)
wrf_geo_sex_plot$upper95 <- as.numeric(wrf_geo_sex_plot$upper95)


## ggplot
  print_plot <- ggplot(wrf_geo_sex_plot,
    aes(x = sex_cat, y = odds_ratio, color = pm_method), na.rm = T) +
    geom_point(position = position_dodge(width = 0.5), na.rm = T) + 
    geom_errorbar(aes(ymin=lower95, ymax=upper95), 
                  position = position_dodge(width = 0.5), width = 0.2, na.rm =T) +
    # custom color 
    scale_color_manual(name = "Smoke-Estimation Method", 
                       values = c("red", "blue", "#32115C"),
                       guide = guide_legend(title.position = "top", title.hjust = 0.5)) +
    facet_wrap(~outcome, nrow = 3, scales = "free") +
    geom_hline(yintercept = 1, linetype=2) +
    #ggtitle('Association Between PM2.5 from \n Wildfire Smoke on Hospitalizations') +
    ylab(expression(paste("Odds Ratio for 10g/m"^3, " Increase in PM"[2.5]))) +
    #ylim(0, 2) +
    xlab('Sex') +
    # plot theme
    theme(panel.background = element_rect(fill = 'white', colour = 'black'),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    # strip element
    strip.background = element_rect(colour=NA, fill=NA),
    panel.border = element_rect(fill = NA, color = "black"),
    # facet text size
    strip.text = element_text(size = 10),
    # axis element
    #axis.text.x = element_blank(),
    #axis.title.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.title.y = element_text(angle = 90),
    # legend elements
    legend.position = "bottom")
    #legend.text = element_text(size = 8))


  print(print_plot)
  # save figure
  ggsave("../plot_new/ndc_sex_fig_three.pdf", plot = print_plot, 
       width = 12, height = 8, units = "in")


```


## County-level time series

### County Time series plots of rate

### Prepare (already done in previous time stratified work)

1. Make 10 units' geo smoke variable
2. Make county population variable (to calculate rate)
3. Make weekend/weekday variables

```{r time series, warning=FALSE, message=FALSE, echo=FALSE}
read_path5 <- paste0("../data_new/medication/or_ndc_county_time_series.csv")
or_ndc_county_ts <- read_csv(read_path5)

plot_ts <- ggplot(or_ndc_county_ts, aes(y =rate_per_100k, x = date)) +
           geom_jitter()

print(plot_ts)

# save figure
ggsave("../plot_new/ndc_rate_ts.pdf", plot = plot_ts, 
       width = 12, height = 8, units = "in")


plot_county <- ggplot(or_ndc_county_ts, aes(y =rate_per_100k, x = date)) +
               geom_jitter() + facet_wrap(~county)

plot_county_line <- ggplot(or_ndc_county_ts, aes(y =rate_per_100k, x = date)) +
                    facet_wrap(~county) + geom_line()

print(plot_county)
print(plot_county_line)
# save figure
ggsave("../plot_new/ndc_county_rate_ts.pdf", plot = plot_county, 
       width = 12, height = 8, units = "in")
ggsave("../plot_new/ndc_county_rate_ts_line.pdf", plot = plot_county_line, 
       width = 12, height = 8, units = "in")


### check if the time series has the association with get smoke
a <- glm(rate_per_100k ~ geo_smk_pm10, data = or_ndc_county_ts, family = "poisson")
summary(a)

plot_health_smk <- ggplot(or_ndc_county_ts, aes(x = geo_smk_pm10, y = log(rate_per_100k+0.1))) +
  geom_point(aes(colour = c("red")), alpha = 0.2,  size = 1) + 
  # scale_colour_manual(values = c("red", "blue")) +
  # truncated y axis
  #scale_y_continuous(limits = c(0, 1.5)) +
  # facet_wrap(~county, scale  = "free") +
  ylab("Log Outcome Rate per 100,000 Persons") +
  xlab("GWR Smoke PM2.5 per 10*10ug/m^3") +
  theme_bw()  

# unnecessary
plot_county_health_smk <- ggplot(or_ndc_county_ts, aes(x = geo_smk_pm10, y = log(rate_per_100k+0.1))) +
  geom_point(aes(colour = county), alpha = 0.2,  size = 1) + 
  # scale_colour_manual(values = c("red", "blue")) +
  # truncated y axis
  #scale_y_continuous(limits = c(0, 1.5)) +
  facet_wrap(~county, scale  = "free") +
  ylab("Log Outcome Rate per 100,000 Persons") +
  xlab("GWR Smoke PM2.5 per 10*10ug/m^3") +
  theme_bw()  

plot(plot_health_smk)
plot(plot_county_health_smk)

ggsave("../plot_new/ndc_rate_health_smk.pdf", plot = plot_health_smk, 
       width = 12, height = 8, units = "in")

ggsave("../plot_new/ndc_county_rate_health_smk.pdf", plot = plot_county_health_smk, 
       width = 12, height = 8, units = "in")


```

### Standard Regression Model (Relative Risk)

1. Fixed-Quasipoisson
2. Fixed-Poisson
3. Mixed-Poisson

```{r regression model q, message=FALSE, echo=FALSE}
# create empty dataframe
rr_df <- data.frame(matrix(nrow = 3, ncol = 5))
colnames(rr_df) <- c("method", "outcome", "rel_risk", "lower_95", "upper_95")

# vector of outcomes
outcome_list <- "n_obs"

# methods
rr_df[,1] <- c("Fixed-Quasipoisson", "Fixed-Poisson", "Mixed-Poisson")

# names 
outcome_names <- c('Inhalers')

# populate outcome column
rr_df[,2] <- factor(outcome_names, levels=unique(outcome_names))

## quasipoisson
smk_est_fq <- tidy(glm(as.formula(paste0(outcome_list, 
    "~ geo_smk_pm10 + wrf_temp_county + county + 
    day + offset(log(pop))")), 
    or_ndc_county_ts, family="quasipoisson"))[2, ]
 
rr_fq <- c(round(exp(smk_est_fq[1,2]),5),
         round(exp(smk_est_fq[1,2]-1.96*smk_est_fq[1,3]),5),
         round(exp(smk_est_fq[1,2]+1.96*smk_est_fq[1,3]),5))

rr_df[1,3:5] <- rr_fq

## poisson
smk_est_fp <- tidy(glm(as.formula(paste0(outcome_list, 
    "~ geo_smk_pm10 + wrf_temp_county + county + 
    day + offset(log(pop))")), 
    or_ndc_county_ts, family="poisson"))[2, ]
 
rr_fp <- c(round(exp(smk_est_fp[1,2]),5),
         round(exp(smk_est_fp[1,2]-1.96*smk_est_fp[1,3]),5),
         round(exp(smk_est_fp[1,2]+1.96*smk_est_fp[1,3]),5))

rr_df[2,3:5] <- rr_fp

## mixed
smk_est_mp <- tidy(glmer(as.formula(paste0(outcome_list, 
    "~ geo_smk_pm10 + wrf_temp_county + (1|county) + 
    day + offset(log(pop))")), 
    or_ndc_county_ts, family="poisson"))[2, ]
 
rr_mp <- c(round(exp(smk_est_mp[1,2]),5),
         round(exp(smk_est_mp[1,2]-1.96*smk_est_mp[1,3]),5),
         round(exp(smk_est_mp[1,2]+1.96*smk_est_mp[1,3]),5))

rr_df[3,3:5] <- rr_mp

rr_df

plot_rr <- ggplot(rr_df, aes(x=method, y = rel_risk)) +
  geom_point() +
  geom_errorbar(aes(ymin=lower_95, ymax=upper_95), width = 0.2) +
  geom_hline(yintercept = 1, linetype = 2, colour = "red") +
  theme(
   panel.background = element_rect(fill = 'white', colour = 'black'),
   panel.grid.major = element_blank(),
   panel.grid.minor = element_blank(),
   axis.text.x = element_text(angle = 90, vjust = .75)) +
  ylab("Relative Risk") +
  xlab("Outcome") +
  ggtitle("Relative Risk for a 10ug/m^3 increase PM2.5 estimated via GWR Smoke")

print(plot_rr)

ggsave("../plot_new/ndc_rr_geo.pdf", plot = plot_rr, 
       width = 12, height = 8, units = "in")

```



## Distributed Lag Model

### Lag 1

Remove the missing values for GWR smoke. 
But I use GWR smoke of zip for the case crossover study.

```{r DLM, echo = FALSE, message=FALSE, warning=FALSE}
read_path8 <- paste0("../data_new/county_data/zip_to_county_new.csv")
or_zip_to_county <- read_csv(read_path8)

read_path9 <- paste0("../data_new/county_data/or_census_pop_est_county.csv")
or_pop <- read_csv(read_path9)

or_pop <- or_pop %>%
  rename(county = GEO_display_label, pop = respop72013) %>%
  select(county, pop) 
or_pop$county <- gsub(" County, Oregon", "", as.character(factor(or_pop$county)))

inhaler_ndc_lag_df <- inhaler_ndc_df %>%
  left_join(or_zip_to_county, by = "ZIPCODE") %>%
  left_join(or_pop, by = "county") %>%
  mutate(day = ifelse(weekdays(date) == "Monday" |
                      weekdays(date) == "Tuesday" |
                      weekdays(date) == "Wednesday"|
                      weekdays(date) == "Thursday"|
                      weekdays(date) == "Friday", "weekday",
               ifelse(weekdays(date) == "Saturday" |
                      weekdays(date) == "Sunday", "weekend", NA))) %>%
  mutate(geo_smk_pm10_zip = geo_smk_pm_zip/10,
         geo_smk_pm10_lag1_zip =geo_smk_pm_lag1_zip/10,
         geo_smk_pm10_lag2_zip =geo_smk_pm_lag2_zip/10,
         geo_smk_pm10_lag3_zip =geo_smk_pm_lag3_zip/10,
         geo_smk_pm10_lag4_zip =geo_smk_pm_lag4_zip/10,
         geo_smk_pm10_lag5_zip =geo_smk_pm_lag5_zip/10,
         geo_smk_pm10_lag6_zip =geo_smk_pm_lag6_zip/10,
         geo_smk_pm10_lag7_zip =geo_smk_pm_lag7_zip/10) %>%
  filter(!is.na(geo_smk_pm10_lag7_zip))

inhaler_ndc_lag_df$day[which(inhaler_ndc_lag_df$date=="2013-05-27")] <- "weekend"
inhaler_ndc_lag_df$day[which(inhaler_ndc_lag_df$date=="2013-07-04")] <- "weekend"
inhaler_ndc_lag_df$day[which(inhaler_ndc_lag_df$date=="2013-09-02")] <- "weekend"                           

  
which(colnames(inhaler_ndc_lag_df)=="geo_smk_pm10_zip") # 159
which(colnames(inhaler_ndc_lag_df)=="geo_smk_pm10_lag1_zip") # 160

inhaler_ndc_lag <- inhaler_ndc_lag_df %>%
  select(159, 160:166) # GWR-method
  
lag_max <- 7
n <- length(inhaler_ndc_lag[,1])

inhaler_ndc_lag <- as.matrix(inhaler_ndc_lag)


B <- ns(0:lag_max, df =3, intercept=TRUE) # or 3?

# the nrow B should equal ncol(pm)
dim(B)
dim(inhaler_ndc_lag)

inhaler_ndc_lag_B <- inhaler_ndc_lag%*%B
fit <- clogit(outcome ~ inhaler_ndc_lag_B + wrf_temp_zip + strata(personkey), inhaler_ndc_lag_df)

coef(fit)
summary(fit)

dlparms <- grep("inhaler_ndc_lag_B",names(coef(fit)))
DLestimate<- data.frame(estimate=B%*%coef(fit)[dlparms])  
DLvar <- B%*%vcov(fit)[dlparms,dlparms]%*%t(B)
DLestimate$SE <- sqrt(diag(DLvar))
DLestimate$lower <- DLestimate$estimate - DLestimate$SE * 1.96
DLestimate$upper <- DLestimate$estimate + DLestimate$SE * 1.96

DLestimate$estimate <- exp(DLestimate$estimate)
DLestimate$lower <- exp(DLestimate$lower)
DLestimate$upper <- exp(DLestimate$upper)

DLestimate

DLestimate$lag <- 0:lag_max
p <- ggplot(DLestimate, aes(x=lag, y=estimate, ymin=lower, ymax=upper))
p <- p + geom_ribbon(alpha=.5) + geom_line(size=2)
p <- p + geom_line(aes(x=lag), linetype=2, size=2)
p <- p + theme_bw()
# p

DLestimate<- data.frame(estimate=B%*%coef(fit)[dlparms])

cumulative <- sum(DLestimate$estimate)
cumulative
## [1] 0.009141771
cumulative_se <- sqrt(sum(DLvar))
cumulative_se
## [1] 0.000955469
cumulative_CI <- cumulative + cumulative_se * c(-1.96, 1.96)
cumulative_CI
## [1] 0.007269052 0.011014490



## mixed model
mod <-glmer(outcome ~  inhaler_ndc_lag_B + wrf_temp_zip + day + (1|county) + offset(log(pop)),   
            inhaler_ndc_lag_df, family="poisson", control = glmerControl(optimizer = "bobyqa"))

summary(mod)
# check AIC
AIC(mod)
# output distributed lag beta parameters
dlparms <- mod@beta[2:4]
# estimate distributed lag values for each day
dl_estimates <- data.frame(estimate = B %*% dlparms)

# covariance matrix for knots (need to convert to matrix object)
cov_mat <- as.matrix(vcov(mod)[2:4,2:4]) 

# estimate variance of splines
dl_var <- B%*%cov_mat%*%t(B)

# calculate standard error for each lag value
dl_estimates$stderr <- sqrt(diag(dl_var))

# calculate lower and upper bounds
dl_estimates$lower_bound <- dl_estimates$estimate+dl_estimates$stderr*qt(1-0.975,
  df=df.residual(mod))  
dl_estimates$upper_bound <- dl_estimates$estimate+dl_estimates$stderr*qt(0.975,
  df=df.residual(mod))  


# estimate relative risk and 95%CI from beta
inhaler_dl_rr <- dl_estimates %>% 
  mutate(estimate = exp(estimate),
         lower_bound = exp(lower_bound),
         upper_bound = exp(upper_bound),
         lag = 0:7)

# estimate cumulative effect
cumulative <- sum(dl_estimates$estimate)
cumulative

# estimate cumulative effect stnd error
cumulative_se <- sqrt(sum(dl_var))
cumulative_se

# estimate cumulative CI
cumulative_ci <- cumulative+cumulative_se*qt(c(1-0.975,0.975), 
                                             df=df.residual(mod))
cumulative_ci

exp(cumulative)
exp(cumulative_ci)

# plot 
p <- ggplot(inhaler_dl_rr, aes(x=lag, y=estimate, 
                              ymin=lower_bound, ymax=upper_bound)) +
  geom_ribbon(alpha = 0.5) +
  geom_line(size=2)

p
```

### Find the smallest of AIC with df from 3 to 6

```{r, message=FALSE, echo=FALSE}
# create fit matrix
fit_mat <- matrix(NA, nrow=4, ncol=6)
colnames(fit_mat) <- c("outcome", "exposure", "fit_mix", "df", "aic", "fit_fix")

# fill outcome name in first column
fit_mat[,1] <- "inhalers"
# fill in exposure (geo smoke)
fit_mat[,2] <- "geo_smk10"
# fit type
fit_mat[,3] <- "ns"
  
# 2 df will not work for a spline, going from 3 to 6 df
  for(h in 3:6){ # start loop for df

    # fitting a natural spline for lag with 5 knots?
    fit_mat[h-2, 4] <- degree_freedom <- h

    # define basis b using natural spline function
    b <- ns(0:7, df = degree_freedom, intercept = T)
    
    # multiply lagged pm matrix by basis
    pm_b <- inhaler_ndc_lag %*% b
    
    # fit mixed model
    mod <-glmer(outcome ~  pm_b + (1|county) + offset(log(pop)), inhaler_ndc_lag_df, family="poisson", control = glmerControl(optimizer = "bobyqa"))
    
    # fixed mod
    fixed_mod <- glm(outcome ~ pm_b + county + offset(log(pop)), inhaler_ndc_lag_df, 
                     family = "poisson")
    
    
    AIC(mod)
    AIC(fixed_mod)
    # fill AIC
    fit_mat[h-2,5] <- round(AIC(mod),5)
    fit_mat[h-2,6] <- round(AIC(fixed_mod),5)

    } # end model fit loop
  

# now that we have a range of df/knots, I want to filter to the minimum aic
# for each outcome and print out that value in a table

fit_mat

lag_spline_best_fit <- as_tibble(fit_mat) %>%  
  slice(which.min(aic)) # df of 3 has the smallest AIC

# kable
knitr::kable(lag_spline_best_fit, caption = paste0("Distributed lag spline",
  "degree of freedom best fit by AIC for mixed model approach"))
```

### Compare fixed and mixed models of df 3 and 4

```{r compare mixed and fixed, message=FALSE, echo=FALSE}

## degree of 3 or 4, mixed or fixed
degree_freedom <- 3

# define basis b using natural spline function
b <- ns(0:7, df = degree_freedom, intercept = T)
    
# multiply lagged pm matrix by basis
pm_b <- inhaler_ndc_lag %*% b

mod <-glmer(outcome ~  pm_b + (1|county) + wrf_temp_zip + offset(log(pop)), inhaler_ndc_lag_df, family="poisson",
            control = glmerControl(optimizer = "bobyqa"))
    
dlparms <- mod@beta[2:(1+degree_freedom)]
# estimate distributed lag values for each day
dl_estimates <- data.frame(estimate = b %*% dlparms)

# covariance matrix for knots (need to convert to matrix object)
cov_mat <- as.matrix(vcov(mod)[2:(1+degree_freedom),2:(1+degree_freedom)]) 

# estimate variance of splines
dl_var <- b%*%cov_mat%*%t(b)

# calculate standard error for each lag value
dl_estimates$stderr <- sqrt(diag(dl_var))

# calculate lower and upper bounds
dl_estimates$lower_bound <- dl_estimates$estimate+dl_estimates$stderr*qt(1-0.975,
  df=df.residual(mod))  
dl_estimates$upper_bound <- dl_estimates$estimate+dl_estimates$stderr*qt(0.975,
  df=df.residual(mod))  


# estimate relative risk and 95%CI from beta
inhaler_dl_rr <- dl_estimates %>% 
  mutate(estimate = exp(estimate),
         lower_bound = exp(lower_bound),
         upper_bound = exp(upper_bound),
         lag = 0:7)

# estimate cumulative effect
cumulative <- sum(dl_estimates$estimate)
cumulative

# estimate cumulative effect stnd error
cumulative_se <- sqrt(sum(dl_var))
cumulative_se

# estimate cumulative CI
cumulative_ci <- cumulative+cumulative_se*qt(c(1-0.975,0.975), 
                                             df=df.residual(mod))
cumulative_ci

exp(cumulative)
exp(cumulative_ci)

# plot 
p3_mix <- ggplot(inhaler_dl_rr, aes(x=lag, y=estimate, 
                              ymin=lower_bound, ymax=upper_bound)) +
  geom_ribbon(alpha = 0.5) +
  geom_line(size=2)



fixed_mod <- glm(outcome ~ pm_b + county + wrf_temp_zip + offset(log(pop)), inhaler_ndc_lag_df, 
                     family = "poisson")

dlparms <- fixed_mod$coefficients[2:4]
# estimate distributed lag values for each day
dl_estimates <- data.frame(estimate = b %*% dlparms)

# covariance matrix for knots (need to convert to matrix object)
cov_mat <- as.matrix(vcov(fixed_mod)[2:4,2:4]) 

# estimate variance of splines
dl_var <- b%*%cov_mat%*%t(b)

# calculate standard error for each lag value
dl_estimates$stderr <- sqrt(diag(dl_var))

# calculate lower and upper bounds
dl_estimates$lower_bound <- dl_estimates$estimate+dl_estimates$stderr*qt(1-0.975,
  df=df.residual(fixed_mod))  
dl_estimates$upper_bound <- dl_estimates$estimate+dl_estimates$stderr*qt(0.975,
  df=df.residual(fixed_mod))  


# estimate relative risk and 95%CI from beta
inhaler_dl_rr <- dl_estimates %>% 
  mutate(estimate = exp(estimate),
         lower_bound = exp(lower_bound),
         upper_bound = exp(upper_bound),
         lag = 0:7)

# estimate cumulative effect
cumulative <- sum(dl_estimates$estimate)
cumulative

# estimate cumulative effect stnd error
cumulative_se <- sqrt(sum(dl_var))
cumulative_se

# estimate cumulative CI
cumulative_ci <- cumulative+cumulative_se*qt(c(1-0.975,0.975), 
                                             df=df.residual(fixed_mod))
cumulative_ci

exp(cumulative)
exp(cumulative_ci)

# plot 
p3_fix <- ggplot(inhaler_dl_rr, aes(x=lag, y=estimate, 
                              ymin=lower_bound, ymax=upper_bound)) +
  geom_ribbon(alpha = 0.5) +
  geom_line(size=2)

p3_fix
p3_mix


## df = 4
degree_freedom <- 4

# define basis b using natural spline function
b <- ns(0:7, df = degree_freedom, intercept = T)
    
# multiply lagged pm matrix by basis
pm_b <- inhaler_ndc_lag %*% b

mod <-glmer(outcome ~  pm_b + (1|county) + wrf_temp_zip + offset(log(pop)), inhaler_ndc_lag_df, family="poisson",
            control = glmerControl(optimizer = "bobyqa"))
    
dlparms <- mod@beta[2:5]
# estimate distributed lag values for each day
dl_estimates <- data.frame(estimate = b %*% dlparms)

# covariance matrix for knots (need to convert to matrix object)
cov_mat <- as.matrix(vcov(mod)[2:5,2:5]) 

# estimate variance of splines
dl_var <- b%*%cov_mat%*%t(b)

# calculate standard error for each lag value
dl_estimates$stderr <- sqrt(diag(dl_var))

# calculate lower and upper bounds
dl_estimates$lower_bound <- dl_estimates$estimate+dl_estimates$stderr*qt(1-0.975,
  df=df.residual(mod))  
dl_estimates$upper_bound <- dl_estimates$estimate+dl_estimates$stderr*qt(0.975,
  df=df.residual(mod))  


# estimate relative risk and 95%CI from beta
inhaler_dl_rr <- dl_estimates %>% 
  mutate(estimate = exp(estimate),
         lower_bound = exp(lower_bound),
         upper_bound = exp(upper_bound),
         lag = 0:7)

# estimate cumulative effect
cumulative <- sum(dl_estimates$estimate)
cumulative

# estimate cumulative effect stnd error
cumulative_se <- sqrt(sum(dl_var))
cumulative_se

# estimate cumulative CI
cumulative_ci <- cumulative+cumulative_se*qt(c(1-0.975,0.975), 
                                             df=df.residual(mod))
cumulative_ci

exp(cumulative)
exp(cumulative_ci)

# plot 
p4_mix <- ggplot(inhaler_dl_rr, aes(x=lag, y=estimate, 
                              ymin=lower_bound, ymax=upper_bound)) +
  geom_ribbon(alpha = 0.5) +
  geom_line(size=2)


fixed_mod <- glm(outcome ~ pm_b + county + wrf_temp_zip + offset(log(pop)), inhaler_ndc_lag_df, 
                     family = "poisson")

dlparms <- fixed_mod$coefficients[2:5]
# estimate distributed lag values for each day
dl_estimates <- data.frame(estimate = b %*% dlparms)

# covariance matrix for knots (need to convert to matrix object)
cov_mat <- as.matrix(vcov(fixed_mod)[2:5,2:5]) 

# estimate variance of splines
dl_var <- b%*%cov_mat%*%t(b)

# calculate standard error for each lag value
dl_estimates$stderr <- sqrt(diag(dl_var))

# calculate lower and upper bounds
dl_estimates$lower_bound <- dl_estimates$estimate+dl_estimates$stderr*qt(1-0.975,
  df=df.residual(fixed_mod))  
dl_estimates$upper_bound <- dl_estimates$estimate+dl_estimates$stderr*qt(0.975,
  df=df.residual(fixed_mod))  


# estimate relative risk and 95%CI from beta
inhaler_dl_rr <- dl_estimates %>% 
  mutate(estimate = exp(estimate),
         lower_bound = exp(lower_bound),
         upper_bound = exp(upper_bound),
         lag = 0:7)

# estimate cumulative effect
cumulative <- sum(dl_estimates$estimate)
cumulative

# estimate cumulative effect stnd error
cumulative_se <- sqrt(sum(dl_var))
cumulative_se

# estimate cumulative CI
cumulative_ci <- cumulative+cumulative_se*qt(c(1-0.975,0.975), 
                                             df=df.residual(fixed_mod))
cumulative_ci

exp(cumulative)
exp(cumulative_ci)

# plot 
p4_fix <- ggplot(inhaler_dl_rr, aes(x=lag, y=estimate, 
                              ymin=lower_bound, ymax=upper_bound)) +
  geom_ribbon(alpha = 0.5) +
  geom_line(size=2)

p4_fix
p4_mix

ggsave("../plot_new/ndc_p3_mix.pdf", plot = p3_mix, 
       width = 12, height = 8, units = "in")
ggsave("../plot_new/ndc_p4_mix.pdf", plot = p4_mix, 
       width = 12, height = 8, units = "in")

ggsave("../plot_new/ndc_p3_fix.pdf", plot = p3_fix, 
       width = 12, height = 8, units = "in")
ggsave("../plot_new/ndc_p4_fix.pdf", plot = p4_fix, 
       width = 12, height = 8, units = "in")


```


Note I get some warnings (including max grade convergence issues), slightly different answers in best fit, and it takes about 18 minutes to run. Consider running in parallel.
I suspect the convergence issues are likely due to the same state/counties with small sample size and few outcome observations and lack of variability between exposure/outcome.
Going to fit what I have now, take a walk, and see what comes out. First thing to do is find cumulative effect, then lagged day effects.

```{r, message=FALSE, echo=FALSE, include=FALSE, eval=FALSE}
# create a dataframe that contains cumulative estimates for each outcome
cumulative_df <- as_tibble(matrix(NA, nrow=0, ncol=4))
colnames(cumulative_df) <- c("outcome", "rel_risk", "lower_95", "upper_95")

# create a dataframe that contains the distributed lag estimates for each outcome
dist_lag_df <- as_tibble(matrix(NA,  nrow = 0, ncol = 5))
colnames(dist_lag_df) <- c("outcome", "lag", "rel_risk", 
                                  "lower_95", "upper_95")

# loop through best fit df

    # create empty matrix two empty matrices to fill
    cumul_val <- as_tibble(matrix(NA, nrow=1, ncol=4))
    colnames(cumul_val) <- c("outcome", "rel_risk", "lower_95", "upper_95")
    
    dl_val <- as_tibble(matrix(NA, nrow=8, ncol=5))
    colnames(dl_val) <- c("outcome", "lag", "rel_risk", 
                                  "lower_95", "upper_95")
    
    # easiest to set out the parameters from the start
    outcome <- "inhalers"
    degree_freedom <- as.numeric(lag_spline_best_fit[4])

    # define basis b using natural spline function
    b <- ns(0:7, df = degree_freedom, intercept = T)
    
    # multiply lagged pm matrix by basis
    pm_b <- inhaler_ndc_lag %*% b
    
    # fit mixed model
     mod <-glmer(outcome ~  inhaler_ndc_lag_B + wrf_temp_zip + day + (1|county) + offset(log(pop)), inhaler_ndc_lag_df, family="poisson", control = glmerControl(optimizer = "bobyqa"))

    mod
    # output distributed lag beta parameters; this will change based on DF
    dlparms <- mod@beta[2:(1+degree_freedom)]
    # estimate distributed lag values for each day
    dl_estimates <- data.frame(estimate = b %*% dlparms)
    
    # covariance matrix for knots (need to convert to matrix object)
    cov_mat <- as.matrix(vcov(mod)[2:(1+degree_freedom),2:(1+degree_freedom)]) 
    # estimate variance of splines
    dl_var <- b%*%cov_mat%*%t(b)
    # calculate standard error for each lag value
    dl_estimates$stderr <- sqrt(diag(dl_var))
    # calculate lower and upper bounds
    dl_estimates$lower_bound <- dl_estimates$estimate+dl_estimates$stderr*qt(1-0.975,
      df=df.residual(mod))  
    dl_estimates$upper_bound <- dl_estimates$estimate+dl_estimates$stderr*qt(0.975,
      df=df.residual(mod))  
    
    # estimate cumulative effect ----
    cumulative <- sum(dl_estimates$estimate)
    # estimate cumulative effect stnd error
    cumulative_se <- sqrt(sum(dl_var))
    # estimate cumulative CI
    cumulative_ci <- cumulative+cumulative_se*qt(c(1-0.975,0.975), 
                                                 df=df.residual(mod))
    # fill tibbles and bind in to larger dataframes ----
    # outcome
    cumul_val[1,1] <- outcome
    # cumulative rel risk
    cumul_val[1,2] <- exp(cumulative)
    # cumulative 95% CI
    cumul_val[1,3:4] <- exp(cumulative_ci)
    # bind to cumulative dataframe
    cumulative_df <- rbind(cumulative_df, cumul_val)

    # lag vals (this step is redundant)
    dl_val[,1] <- outcome
    dl_val[,2] <- 0:7
    dl_val[,3] <- exp(dl_estimates[,1])
    dl_val[,4] <- exp(dl_estimates[,3])
    dl_val[,5] <- exp(dl_estimates[,4])
    
    # bind in with overall df
    dist_lag_df <- rbind(dist_lag_df, dl_val)


# print table of cumulative effects
knitr::kable(cumulative_df, caption = paste0("Cumulative Effect for a 10 ug/m^3 increase in GWR smoke lagged days 0-7 mixed model approach"))

# plot distributed lag effects
ggplot(dist_lag_df, aes(x=lag, y=rel_risk)) +
  geom_line(colour = "blue") +
  geom_ribbon(aes(ymin = lower_95, ymax = upper_95), fill = "blue", alpha = 0.3) + 
  scale_y_continuous(limits = c(0.98, 1.06)) +
  scale_x_continuous(breaks = c(seq(0, 7,by=1))) +
  geom_hline(yintercept = 1, linetype = 2, colour = "red") +
  facet_wrap(~ outcome) +
  ggtitle(paste0("Distributed lag association between a 10 ug/m^3",
                 " increase in GWR smoke PM2.5 and cardiopulmonary outcomes")) +
  ylab("Relative Risk for a 10 ug/m^3 increase in GWR smoke (fixed)") +
  xlab("Lagged Days") +
  theme_bw()

```

## Distributed Lag -- Casecrossover Analysis

### Lag 

### 1. For Overall Plot

```{r overall lags, warning =F, echo = F, results='asis'} 
# dataframe list
method_list <- c('Geo-Weighted Smoke')

lag_list <- c("Lag 1", "Lag 2", "Lag 3", "Lag 4", "Lag 5", "Lag 6", "Lag 7")

# dataframe to loop through
inhaler_ndc <- data.frame(inhaler_ndc) 
#  filter(!is.na(geo_smk_pm_lag1_zip))

# outcome name
outcome <- "Asthma Inhalers"

# data wrangling ----
# Producing conditional logit model estimates loop 

# extract covariates from dataframe
covariates_df <- inhaler_ndc[, c(1:26, 74:79)] # 94:156 is lag
  
# extract pm values and divide by 10 and ordered
which(colnames(inhaler_ndc)=="geo_smk_pm_lag1_zip") # 136
which(colnames(inhaler_ndc)=="wrf_temp_lag1_zip") # 150
pm_estimates_df <- inhaler_ndc[, 136:142]/10  # create 10 unit increases
temp_estimates_df <- inhaler_ndc[, 150:156]  # temperature

# new loop for age categories

# empty matrix (12 x 10 matrix)
point_estimates <- matrix(nrow = 7, ncol = 10, byrow = T)
    
colnames(point_estimates) <- c('outcome', 'pm_method',  'lag', 'n', 'n_events', 
                                   'odds_ratio', 'lower95', 'upper95', 'se', 'p_val')    
  
# fill in the outcome namedataframe before method loop
point_estimates[, 1] <- outcome

for (i in 1:7){
geo_lag <- i + 32 
temp_lag <- i + 39

# dataframe for analysis creation
# bind columns back together 
df_analysis <- cbind(covariates_df, pm_estimates_df, temp_estimates_df) 

df_analysis <- df_analysis %>% 
  # remove missing pm values
  filter(!is.na(df_analysis[geo_lag])) %>% 
  # the following code makes sure that the counterfactual values retained are 
  # symetric in that number of obs before = number of obs after
  mutate(obs_diff_admission = (fromdate - date)/7) 
  # dataframe is already for the entire fire season, so I don't need to subset anymore
  
# second loop to run a model for each pm estimation method


  # variable to model 
  var_name <- colnames(df_analysis[geo_lag])
      
  # set row number to fill
  row_n <- i
      
  # only run the model if the dataframe has observations
  if(nrow(df_analysis) != 0){
  # conditional logistic regression model
  mod <- clogit(outcome ~ df_analysis[[geo_lag]] + df_analysis[[temp_lag]] + strata(personkey), df_analysis)
      
  # populate matrix
  point_estimates[row_n, 2] <- method_list
  point_estimates[row_n, 3] <- lag_list[row_n]
  point_estimates[row_n, 4] <- mod$n
  point_estimates[row_n, 5] <- mod$nevent
  # odds ratio
  point_estimates[row_n, 6] <- round(exp(summary(mod)$coefficient[1,1]), 3)

  # 95% lower bound
  point_estimates[row_n, 7] <- round(exp((summary(mod)$coefficient[1,1]) -                                                                             1.96*(summary(mod)$coefficient[1,3])), 3)
  # 95% upper bound
  point_estimates[row_n, 8] <- round(exp((summary(mod)$coefficient[1,1]) +
                                        1.96*(summary(mod)$coefficient[1,3])), 3)
  # standard error
  point_estimates[row_n, 9] <- round(summary(mod)$coefficient[1,3], 4)
  # p val
  point_estimates[row_n, 10] <- round(summary(mod)$coefficient[1,5], 4)
      
  # create else statement that fills matrix with missing so I still have the row
  # in the final dataframe
  } else {point_estimates[row_n, 3] <- method_list[row_n]
          point_estimates[row_n, 4] <- 0
          point_estimates[row_n, 5] <- 0
          point_estimates[row_n, c(6:10)] <- 99 } # end 'if else' statement
  
}
# save point estimates as a dataframe
combined_point_est_df <- as_data_frame(point_estimates)



wrf_geo_lag <- combined_point_est_df %>% 
  select(3, 5:8) %>% 
  mutate(odds_ratio = ifelse(odds_ratio == 99, "--", odds_ratio),
         lower95 = ifelse(lower95 == 99, "--", lower95),
         upper95 = ifelse(upper95 == 99, "--", upper95))


tab <- htmlTable(txtRound(wrf_geo_lag, digits = 3, 1:3), 
         caption = "Association between a 10 ug/m^3 in PM2.5 three smoke method and pharmacy outcomes",
         # row group by outcome
         rgroup = "Asthma Inhalers",
         n.rgroup = c(rep(1, 1)), # 6 rows for each age cat for each outcome
         # column headers
         header = c("Lag", "Events",
                    "OR&dagger;", "Lower", "Upper"),
         # column spanner
         cgroup = c("", "95% CI"), 
         n.cgroup = c(3, 2),
         padding.rgroup = "&nbsp;&nbsp;",
         css.cell = "padding-left: 0.5em; padding-right: .5em;", # cell space
         align = "llcccc", # column alignment,
         tfoot="&dagger; Referent periods matched to events on same day of week within May to September fire season."
         ) # end table
  
print(tab)
  
combined_point_est_df_new <- combined_point_est_df %>%
  mutate(n_events_new = ifelse(as.numeric(n_events)>=100, n_events,
                        ifelse(as.numeric(n_events)<100, "0", NA))) %>%
  select(-n_events) %>%
  rename(n_events = n_events_new)


# ggplot of odds ratios, facet wrapped by outcomes -----
# convert variables from character to either numeric or factor
# factor preserves the order of the variable
wrf_geo_lag_plot <- combined_point_est_df_new %>% 
  # filter columns to just geo-smk
 #  filter(pm_method == "GWR Smoke" | pm_method == "WRF-Chem Smoke") %>% 
  # do not plot results with less than 15 events, create missing vals
  # in mutate
  mutate(odds_ratio = ifelse(as.numeric(n_events) < 15, 
                             99, odds_ratio),
         lower95 = ifelse(as.numeric(n_events) < 15, 
                             99, lower95),
         upper95 = ifelse(as.numeric(n_events) < 15, 
                             99, upper95)) %>% 
  # subset columns I want to put in to the table
  select(1, 3, 10, 5:7) %>% 
  mutate(odds_ratio = ifelse(odds_ratio == 99, NA, odds_ratio),
         lower95 = ifelse(lower95 == 99, NA, lower95),
         upper95 = ifelse(upper95 == 99, NA, upper95))

# change characters to numeric and factor  
wrf_geo_lag_plot$outcome <- factor(wrf_geo_lag_plot$outcome,
                              levels = unique(wrf_geo_lag_plot$outcome))

wrf_geo_lag_plot$lag <- factor(wrf_geo_lag_plot$lag,
                                levels = unique(wrf_geo_lag_plot$lag))

wrf_geo_lag_plot$n_events <- as.numeric(wrf_geo_lag_plot$n_events)
wrf_geo_lag_plot$odds_ratio <- as.numeric(wrf_geo_lag_plot$odds_ratio)
wrf_geo_lag_plot$lower95 <- as.numeric(wrf_geo_lag_plot$lower95)
wrf_geo_lag_plot$upper95 <- as.numeric(wrf_geo_lag_plot$upper95)


## ggplot 
  print_plot <- ggplot(wrf_geo_lag_plot,
    aes(x = lag, y = odds_ratio, color = lag), na.rm = T) +
    geom_point(position = position_dodge(width = 0.5), na.rm = T) + 
    geom_errorbar(aes(ymin=lower95, ymax=upper95), 
                  position = position_dodge(width = 0.5), width = 0.2, na.rm =T) +
    # custom color 
    scale_color_manual(name = "Geo-smk Lag", 
                       values = c("red", "orange", "yellow", "green", "blue", "#32115C", "purple"),
                       guide = guide_legend(title.position = "top", title.hjust = 0.5)) +
    facet_wrap(~outcome, nrow = 7, scales = "free") +
    geom_hline(yintercept = 1, linetype=2) +
    #ggtitle('Association Between PM2.5 from \n Wildfire Smoke on Hospitalizations') +
    ylab(expression(paste("Odds Ratio for 10g/m"^3, " Increase in PM"[2.5]))) +
    #ylim(0, 2) +
    xlab('Smoke Estimation Method') +
    # plot theme
    theme(panel.background = element_rect(fill = 'white', colour = 'black'),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    # strip element
    strip.background = element_rect(colour=NA, fill=NA),
    panel.border = element_rect(fill = NA, color = "black"),
    # facet text size
    strip.text = element_text(size = 10),
    # axis element
    #axis.text.x = element_blank(),
    #axis.title.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.title.y = element_text(angle = 90),
    # legend elements
    legend.position = "bottom")
    #legend.text = element_text(size = 8))


  print(print_plot)
  # save figure
  ggsave("../plot_new/ndc_health_lag.pdf", plot = print_plot, 
       width = 12, height = 8, units = "in")
  
```

### 2. For Age Category



### 3. For Sex Category


